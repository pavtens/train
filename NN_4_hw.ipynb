{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OGQij9u1eVoj"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "S1AsniZUeVos"
      },
      "outputs": [],
      "source": [
        "class DatasetSeq(Dataset):\n",
        "    def __init__(self, data_dir, train_lang='en'):\n",
        "\n",
        "        with open(data_dir + train_lang + '.train', 'r', encoding='utf-8') as f:\n",
        "            train = f.read().split('\\n\\n')\n",
        "\n",
        "        # delete extra tag markup\n",
        "        train = [x for x in train if not '_ ' in x]\n",
        "\n",
        "        self.target_vocab = {}\n",
        "        self.word_vocab = {}\n",
        "        self.char_vocab = {}\n",
        "\n",
        "        self.encoded_sequences = []\n",
        "        self.encoded_targets = []\n",
        "        self.encoded_char_sequences = []\n",
        "        n_word = 1\n",
        "        n_target = 1\n",
        "        n_char = 1\n",
        "        for line in train:\n",
        "            sequence = []\n",
        "            target = []\n",
        "            chars = []\n",
        "            for item in line.split('\\n'):\n",
        "                if item != '':\n",
        "                    word, label = item.split(' ')\n",
        "\n",
        "                    if self.word_vocab.get(word) is None:\n",
        "                        self.word_vocab[word] = n_word\n",
        "                        n_word += 1\n",
        "                    if self.target_vocab.get(label) is None:\n",
        "                        self.target_vocab[label] = n_target\n",
        "                        n_target += 1\n",
        "                    for char in word:\n",
        "                        if self.char_vocab.get(char) is None:\n",
        "                            self.char_vocab[char] = n_char\n",
        "                            n_char += 1\n",
        "                    sequence.append(self.word_vocab[word])\n",
        "                    target.append(self.target_vocab[label])\n",
        "                    chars.append([self.char_vocab[char] for char in word])\n",
        "            self.encoded_sequences.append(sequence)\n",
        "            self.encoded_targets.append(target)\n",
        "            self.encoded_char_sequences.append(chars)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoded_sequences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return {\n",
        "            'data': self.encoded_sequences[index], # [1, 2, 3, 4, 6] len=5\n",
        "            'char': self.encoded_char_sequences[index],# [[1,2,3], [4,5], [1,2], [2,6,5,4], []] len=5\n",
        "            'target': self.encoded_targets[index], #  (1)\n",
        "        }\n",
        "# seq1 = [1, 2, 3] -> [1, 2, 3, 0]\n",
        "# seq2 = [7, 5, 4, 2]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    data = []\n",
        "    target = []\n",
        "    for item in batch:\n",
        "        data.append(torch.as_tensor(item['data']))\n",
        "        target.append(torch.as_tensor(item['target']))\n",
        "    data = pad_sequence(data, batch_first=True, padding_value=0)\n",
        "    target = pad_sequence(target, batch_first=True, padding_value=0)\n",
        "\n",
        "    return {'data': data, 'target': target}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/sample_data/'\n",
        "train_lang = 'en'\n",
        "dataset = DatasetSeq(data_dir)"
      ],
      "metadata": {
        "id": "bEpfPISKfGt-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fOe83GjneVoy"
      },
      "outputs": [],
      "source": [
        "vocab_len = len(dataset.word_vocab) + 1\n",
        "n_classes = len(dataset.target_vocab) + 1\n",
        "n_chars = len(dataset.char_vocab) + 1\n",
        "cuda_device = 10\n",
        "batch_size = 200\n",
        "device = f'cuda:{cuda_device}' if cuda_device != -1 else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYP5S1oOeVoz"
      },
      "source": [
        "GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2YO1JHQeVo5",
        "outputId": "7cb29918-9fbd-43be-f6dc-506f37d1e5ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "POS_predictor_GRU(\n",
              "  (emb): Embedding(29588, 200)\n",
              "  (gru): GRU(200, 256, batch_first=True)\n",
              "  (classifier): Linear(in_features=256, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "class POS_predictor_GRU(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocab_size: int,\n",
        "                 emb_dim: int,\n",
        "                 hidden_dim: int,\n",
        "                 n_classes: int,\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.gru = nn.GRU(emb_dim, hidden_dim, batch_first=True, bidirectional=False)\n",
        "        self.classifier = nn.Linear(hidden_dim, n_classes, bias=True)\n",
        "\n",
        "    def forward(self, x): # B x T\n",
        "        emb_x = self.emb(x)  # B x T x V\n",
        "        gru_out, _ = self.gru(emb_x)\n",
        "        pred = self.classifier(torch.dropout(gru_out, 0.1, self.training))\n",
        "\n",
        "        return pred\n",
        "\n",
        "model = POS_predictor_GRU(vocab_len, 200, 256, n_classes)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qy6C14YeVo6",
        "outputId": "d0ce1bd1-6ba1-4732-9d74-a3545fc46393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.7545, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2952, grad_fn=<NllLossBackward0>)\n",
            "0\n",
            "tensor(0.2921, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1388, grad_fn=<NllLossBackward0>)\n",
            "1\n",
            "tensor(0.1644, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1657, grad_fn=<NllLossBackward0>)\n",
            "2\n",
            "tensor(0.0773, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1318, grad_fn=<NllLossBackward0>)\n",
            "3\n",
            "tensor(0.0855, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0887, grad_fn=<NllLossBackward0>)\n",
            "4\n",
            "tensor(0.0617, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0783, grad_fn=<NllLossBackward0>)\n",
            "5\n",
            "tensor(0.0503, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0913, grad_fn=<NllLossBackward0>)\n",
            "6\n",
            "tensor(0.0658, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0595, grad_fn=<NllLossBackward0>)\n",
            "7\n",
            "tensor(0.0603, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0552, grad_fn=<NllLossBackward0>)\n",
            "8\n",
            "tensor(0.0396, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0458, grad_fn=<NllLossBackward0>)\n",
            "9\n",
            "tensor(0.0341, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0290, grad_fn=<NllLossBackward0>)\n",
            "10\n",
            "tensor(0.0352, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0576, grad_fn=<NllLossBackward0>)\n",
            "11\n",
            "tensor(0.0304, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0254, grad_fn=<NllLossBackward0>)\n",
            "12\n",
            "tensor(0.0307, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0329, grad_fn=<NllLossBackward0>)\n",
            "13\n",
            "tensor(0.0398, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0192, grad_fn=<NllLossBackward0>)\n",
            "14\n",
            "tensor(0.0175, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0311, grad_fn=<NllLossBackward0>)\n",
            "15\n",
            "tensor(0.0175, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0215, grad_fn=<NllLossBackward0>)\n",
            "16\n",
            "tensor(0.0152, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0256, grad_fn=<NllLossBackward0>)\n",
            "17\n",
            "tensor(0.0120, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0208, grad_fn=<NllLossBackward0>)\n",
            "18\n",
            "tensor(0.0193, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0174, grad_fn=<NllLossBackward0>)\n",
            "19\n"
          ]
        }
      ],
      "source": [
        "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "#dataloder\n",
        "for epoch in range(20):\n",
        "    dataloader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        collate_fn=collate_fn,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    for step, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "        data = batch['data']  # B x T\n",
        "        pred = model(data)\n",
        "        loss = loss_func(pred.view(-1, n_classes), batch['target'].view(-1))\n",
        "        loss.backward()\n",
        "        # if step % 5:\n",
        "        optim.step()\n",
        "\n",
        "        if step % 100 == 0 :\n",
        "            print(loss)\n",
        "    print(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "g43d5tZaeVo8"
      },
      "outputs": [],
      "source": [
        "# inference\n",
        "sequence = [2,36,2,14,4,24]\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    predict = model(torch.tensor(sequence).unsqueeze(0)) # 1 x T x N_classes\n",
        "    labels = predict.argmax(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bATbxRYWUxVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIDRoHRcy3rJ",
        "outputId": "fff8031f-a64b-4462-a546-9a51fef5bd05"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 7, 2, 4, 2, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDKzFILFeVo-",
        "outputId": "99f60845-5f30-4990-84c5-d4991fc8080f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PART', 'DET', 'CCONJ', 'AUX', 'ADP', 'NOUN', 'VERB', 'X', 'DET', 'PART']\n"
          ]
        }
      ],
      "source": [
        "#example\n",
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    predict = model(torch.tensor(tokens).unsqueeze(0)) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    end = datetime.datetime.now() - start\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l] for l in labels])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-9axAhXU2tM"
      },
      "source": [
        "RNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class POS_predictor_RNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocab_size: int,\n",
        "                 emb_dim: int,\n",
        "                 hidden_dim: int,\n",
        "                 n_classes: int,\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn = nn.RNN(emb_dim, hidden_dim, batch_first=True, bidirectional=False)\n",
        "        self.classifier = nn.Linear(hidden_dim, n_classes, bias=True)\n",
        "\n",
        "    def forward(self, x): # B x T\n",
        "        emb_x = self.emb(x)  # B x T x V\n",
        "        rnn_out, _ = self.rnn(emb_x)\n",
        "        pred = self.classifier(torch.dropout(rnn_out, 0.1, self.training))\n",
        "\n",
        "        return pred\n",
        "\n",
        "model_RNN = POS_predictor_RNN(vocab_len, 250, 300, n_classes)\n",
        "model_RNN.train()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sXHe1-DUnHW",
        "outputId": "460d3ed0-23a6-47a3-85fe-2da04d1f1e49"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "POS_predictor_RNN(\n",
              "  (emb): Embedding(29588, 250)\n",
              "  (rnn): RNN(250, 300, batch_first=True)\n",
              "  (classifier): Linear(in_features=300, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optim_RNN = torch.optim.Adam(model_RNN.parameters(), lr=0.001)\n",
        "loss_func_RNN = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(20):\n",
        "    dataloader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        collate_fn=collate_fn,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    for step, batch in enumerate(dataloader):\n",
        "        optim_RNN.zero_grad()\n",
        "        data = batch['data']  # B x T\n",
        "        pred = model_RNN(data)\n",
        "        loss_RNN = loss_func_RNN(pred.view(-1, n_classes), batch['target'].view(-1))\n",
        "        loss_RNN.backward()\n",
        "        # if step % 5:\n",
        "        optim_RNN.step()\n",
        "\n",
        "        if step % 100 == 0 :\n",
        "            print(loss_RNN)\n",
        "    print(epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnGLxO5PUncG",
        "outputId": "32aee049-0a78-46b5-abde-08572ab85f5d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.8381, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1891, grad_fn=<NllLossBackward0>)\n",
            "0\n",
            "tensor(0.1382, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1672, grad_fn=<NllLossBackward0>)\n",
            "1\n",
            "tensor(0.1341, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1784, grad_fn=<NllLossBackward0>)\n",
            "2\n",
            "tensor(0.0883, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1264, grad_fn=<NllLossBackward0>)\n",
            "3\n",
            "tensor(0.0969, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0904, grad_fn=<NllLossBackward0>)\n",
            "4\n",
            "tensor(0.0875, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1147, grad_fn=<NllLossBackward0>)\n",
            "5\n",
            "tensor(0.0720, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0575, grad_fn=<NllLossBackward0>)\n",
            "6\n",
            "tensor(0.0635, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0728, grad_fn=<NllLossBackward0>)\n",
            "7\n",
            "tensor(0.0561, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0491, grad_fn=<NllLossBackward0>)\n",
            "8\n",
            "tensor(0.0499, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0584, grad_fn=<NllLossBackward0>)\n",
            "9\n",
            "tensor(0.0387, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0395, grad_fn=<NllLossBackward0>)\n",
            "10\n",
            "tensor(0.0326, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0456, grad_fn=<NllLossBackward0>)\n",
            "11\n",
            "tensor(0.0385, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0422, grad_fn=<NllLossBackward0>)\n",
            "12\n",
            "tensor(0.0344, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0288, grad_fn=<NllLossBackward0>)\n",
            "13\n",
            "tensor(0.0262, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0257, grad_fn=<NllLossBackward0>)\n",
            "14\n",
            "tensor(0.0239, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0342, grad_fn=<NllLossBackward0>)\n",
            "15\n",
            "tensor(0.0227, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0259, grad_fn=<NllLossBackward0>)\n",
            "16\n",
            "tensor(0.0287, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0192, grad_fn=<NllLossBackward0>)\n",
            "17\n",
            "tensor(0.0180, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0297, grad_fn=<NllLossBackward0>)\n",
            "18\n",
            "tensor(0.0239, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0149, grad_fn=<NllLossBackward0>)\n",
            "19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model_RNN.eval()\n",
        "    predict = model_RNN(torch.tensor(tokens).unsqueeze(0)) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    end = datetime.datetime.now() - start\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l] for l in labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a7n0LazUntQ",
        "outputId": "0fbdd581-29c1-4e99-a5b8-c223a910312b"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PART', 'DET', 'CCONJ', 'NUM', 'ADP', 'NOUN', 'VERB', 'X', 'DET', 'PART']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPNuUDzCpwTB"
      },
      "source": [
        "RNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class POS_predictor_LSTM(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocab_size: int,\n",
        "                 emb_dim: int,\n",
        "                 hidden_dim: int,\n",
        "                 n_classes: int,\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True, bidirectional=False)\n",
        "        self.classifier = nn.Linear(hidden_dim, n_classes, bias=True)\n",
        "\n",
        "    def forward(self, x): # B x T\n",
        "        emb_x = self.emb(x)  # B x T x V\n",
        "        lstm_out, _ = self.lstm(emb_x)\n",
        "        pred = self.classifier(torch.dropout(lstm_out, 0.1, self.training))\n",
        "\n",
        "        return pred\n",
        "\n",
        "model_LSTM = POS_predictor_LSTM(vocab_len, 250, 300, n_classes)\n",
        "model_LSTM.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ2XgoXIpxVQ",
        "outputId": "9fc33afc-74a4-4e7f-c30d-715c6b656c03"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "POS_predictor_LSTM(\n",
              "  (emb): Embedding(29588, 250)\n",
              "  (lstm): LSTM(250, 300, batch_first=True)\n",
              "  (classifier): Linear(in_features=300, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optim_LSTM = torch.optim.Adam(model_LSTM.parameters(), lr=0.001)\n",
        "loss_func_LSTM = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(20):\n",
        "    dataloader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        collate_fn=collate_fn,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    for step, batch in enumerate(dataloader):\n",
        "        optim_LSTM.zero_grad()\n",
        "        data = batch['data']  # B x T\n",
        "        pred = model_LSTM(data)\n",
        "        loss_LSTM = loss_func_LSTM(pred.view(-1, n_classes), batch['target'].view(-1))\n",
        "        loss_LSTM.backward()\n",
        "        # if step % 5:\n",
        "        optim_LSTM.step()\n",
        "\n",
        "        if step % 100 == 0 :\n",
        "            print(loss_LSTM)\n",
        "    print(epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G03sslJypxhR",
        "outputId": "ede404fa-bcb0-47a5-e895-7c517f91f320"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.9761, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3434, grad_fn=<NllLossBackward0>)\n",
            "0\n",
            "tensor(0.3014, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2122, grad_fn=<NllLossBackward0>)\n",
            "1\n",
            "tensor(0.1915, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1530, grad_fn=<NllLossBackward0>)\n",
            "2\n",
            "tensor(0.1157, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1053, grad_fn=<NllLossBackward0>)\n",
            "3\n",
            "tensor(0.1291, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0658, grad_fn=<NllLossBackward0>)\n",
            "4\n",
            "tensor(0.0480, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0557, grad_fn=<NllLossBackward0>)\n",
            "5\n",
            "tensor(0.0707, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0643, grad_fn=<NllLossBackward0>)\n",
            "6\n",
            "tensor(0.0413, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0681, grad_fn=<NllLossBackward0>)\n",
            "7\n",
            "tensor(0.0208, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0427, grad_fn=<NllLossBackward0>)\n",
            "8\n",
            "tensor(0.0384, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0342, grad_fn=<NllLossBackward0>)\n",
            "9\n",
            "tensor(0.0361, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0631, grad_fn=<NllLossBackward0>)\n",
            "10\n",
            "tensor(0.0329, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0424, grad_fn=<NllLossBackward0>)\n",
            "11\n",
            "tensor(0.0368, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0344, grad_fn=<NllLossBackward0>)\n",
            "12\n",
            "tensor(0.0291, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0294, grad_fn=<NllLossBackward0>)\n",
            "13\n",
            "tensor(0.0223, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0330, grad_fn=<NllLossBackward0>)\n",
            "14\n",
            "tensor(0.0099, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0163, grad_fn=<NllLossBackward0>)\n",
            "15\n",
            "tensor(0.0166, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0180, grad_fn=<NllLossBackward0>)\n",
            "16\n",
            "tensor(0.0065, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0127, grad_fn=<NllLossBackward0>)\n",
            "17\n",
            "tensor(0.0118, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0143, grad_fn=<NllLossBackward0>)\n",
            "18\n",
            "tensor(0.0118, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0111, grad_fn=<NllLossBackward0>)\n",
            "19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model_LSTM.eval()\n",
        "    predict = model_LSTM(torch.tensor(tokens).unsqueeze(0)) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    end = datetime.datetime.now() - start\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l] for l in labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQJLbfsd2NFc",
        "outputId": "2821afde-017d-4fa3-df78-b01a7201b29d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PART', 'DET', 'CCONJ', 'CCONJ', 'ADP', 'NOUN', 'VERB', 'X', 'DET', 'PART']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOjick9WQXUd"
      },
      "source": [
        "RNN+char"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn_char(input_data):\n",
        "    data = []\n",
        "    chars = []\n",
        "    targets = []\n",
        "    max_len = 0\n",
        "    for item in input_data:\n",
        "        if len(item['data']) > max_len:\n",
        "            max_len = len(item['data'])\n",
        "        data.append(torch.as_tensor(item['data']))\n",
        "        chars.append(item['char'])\n",
        "        targets.append(torch.as_tensor(item['target']))\n",
        "    chars_seq = [[torch.as_tensor([0]) for _ in range(len(input_data))] for _ in range(max_len)]\n",
        "    for j in range(len(input_data)): #для каждого элемента (словосочетания) в датасете\n",
        "        for i in range(max_len):\n",
        "            if len(chars[j]) > i: #пока длина посл-ти слов 1 элемента (словосочетания) вписывается в макс.длину\n",
        "                chars_seq[i][j] = torch.as_tensor(chars[j][i]) #добавляем слово в словарь\n",
        "    for j in range(max_len):\n",
        "        chars_seq[j] = pad_sequence(chars_seq[j], batch_first=True, padding_value=0) #дозаполняем нулями короткие ССЧ\n",
        "    data = pad_sequence(data, batch_first=True, padding_value=0)\n",
        "    targets = pad_sequence(targets, batch_first=True, padding_value=0)\n",
        "    return {'data': data, 'chars': chars_seq, 'target': targets}"
      ],
      "metadata": {
        "id": "I0Y4zaeBQYa7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CharModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocab_size: int,\n",
        "                 emb_dim: int,\n",
        "                 hidden_dim: int,\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, x): # B x T\n",
        "        emb_x = self.emb(x)  # B x T x V\n",
        "        _, out = self.rnn(emb_x) # 1 x B x Hid\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "TSBADCy6QYiY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class POS_predictorV2Chars(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocab_size: int,\n",
        "                 emb_dim: int,\n",
        "                 hidden_dim: int,\n",
        "                 n_classes: int,\n",
        "                 n_chars: int,\n",
        "                 char_emb_dim: int,\n",
        "                 char_hidden_dim: int,\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.gru = nn.GRU(emb_dim + char_hidden_dim, hidden_dim, batch_first=True, bidirectional=False)\n",
        "        self.classifier = nn.Linear(hidden_dim, n_classes, bias=True)\n",
        "        self.char_rnn = CharModel(n_chars, char_emb_dim, char_hidden_dim)\n",
        "\n",
        "    def forward(self, x, x_chars):  # B x T\n",
        "        emb_x = self.emb(x)  # B x T x V\n",
        "        chars = [self.char_rnn(word.to(emb_x.device)).squeeze().unsqueeze(1) for word in x_chars]\n",
        "        chars = torch.cat(chars, dim=1)\n",
        "        gru_out, _ = self.gru(torch.cat((emb_x, chars), dim=-1))\n",
        "        pred = self.classifier(torch.dropout(gru_out, 0.1, self.training))\n",
        "\n",
        "        return pred"
      ],
      "metadata": {
        "id": "-L_tJI_NQnCd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_char = POS_predictorV2Chars(vocab_len, 200, 256, n_classes, n_chars, 32, 64)\n",
        "model_char.train()\n",
        "\n",
        "optim_char = torch.optim.Adam(model_char.parameters(), lr=0.001)\n",
        "\n",
        "loss_func_char = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(20):\n",
        "    dataloader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        collate_fn=collate_fn_char,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    for step, batch in enumerate(dataloader):\n",
        "        #\n",
        "        optim_char.zero_grad()\n",
        "        data = batch['data']  # B x T\n",
        "        pred = model_char(data, batch['chars'])\n",
        "        loss_char = loss_func_char(pred.view(-1, n_classes), batch['target'].view(-1))\n",
        "        loss_char.backward()\n",
        "        # if step % 5:\n",
        "        optim_char.step()\n",
        "        #\n",
        "        if step % 100 == 0:\n",
        "            print(loss_char)\n",
        "    print(epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NZioMjRQq1p",
        "outputId": "05372d75-0a96-48f7-db65-d2e32996dd43"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.0350, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1693, grad_fn=<NllLossBackward0>)\n",
            "0\n",
            "tensor(0.2545, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1286, grad_fn=<NllLossBackward0>)\n",
            "1\n",
            "tensor(0.1667, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0944, grad_fn=<NllLossBackward0>)\n",
            "2\n",
            "tensor(0.0787, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1035, grad_fn=<NllLossBackward0>)\n",
            "3\n",
            "tensor(0.0560, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0320, grad_fn=<NllLossBackward0>)\n",
            "4\n",
            "tensor(0.0615, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0760, grad_fn=<NllLossBackward0>)\n",
            "5\n",
            "tensor(0.0525, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0476, grad_fn=<NllLossBackward0>)\n",
            "6\n",
            "tensor(0.0522, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0646, grad_fn=<NllLossBackward0>)\n",
            "7\n",
            "tensor(0.0439, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0393, grad_fn=<NllLossBackward0>)\n",
            "8\n",
            "tensor(0.0320, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0376, grad_fn=<NllLossBackward0>)\n",
            "9\n",
            "tensor(0.0353, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0516, grad_fn=<NllLossBackward0>)\n",
            "10\n",
            "tensor(0.0395, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0273, grad_fn=<NllLossBackward0>)\n",
            "11\n",
            "tensor(0.0371, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0353, grad_fn=<NllLossBackward0>)\n",
            "12\n",
            "tensor(0.0313, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0298, grad_fn=<NllLossBackward0>)\n",
            "13\n",
            "tensor(0.0214, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0340, grad_fn=<NllLossBackward0>)\n",
            "14\n",
            "tensor(0.0285, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0216, grad_fn=<NllLossBackward0>)\n",
            "15\n",
            "tensor(0.0159, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0248, grad_fn=<NllLossBackward0>)\n",
            "16\n",
            "tensor(0.0187, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0203, grad_fn=<NllLossBackward0>)\n",
            "17\n",
            "tensor(0.0172, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0186, grad_fn=<NllLossBackward0>)\n",
            "18\n",
            "tensor(0.0160, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0189, grad_fn=<NllLossBackward0>)\n",
            "19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens1 = [dataset.word_vocab[w] for w in words]\n",
        "tokens2 = []\n",
        "for w in words:\n",
        "  tokens2.append([dataset.char_vocab[w[i]] for i in range(len(w))])"
      ],
      "metadata": {
        "id": "__htQ86vjXHs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens3=[]\n",
        "for j in range(len(tokens2)):\n",
        "  tokens3.append(tokens2[j]+[0 for i in range(7-len(tokens2[j]))])"
      ],
      "metadata": {
        "id": "4E3ARdXfm2r0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model_char.eval()\n",
        "    predict = model_char(torch.tensor(tokens1).unsqueeze(1), torch.tensor(tokens3).unsqueeze(0)) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    end = datetime.datetime.now() - start\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l] for l in labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqK8hfmPmu-e",
        "outputId": "031c11fd-9630-42f9-9586-1e27029b554c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PART', 'DET', 'CCONJ', 'AUX', 'ADP', 'NOUN', 'VERB', 'X', 'DET', 'PART']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "8750a921b84a1b624817dbfae33fa28d408c1c697f0b181b4279f7947f553d12"
      }
    },
    "colab": {
      "name": "Копия блокнота \"NN_4_hw.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}