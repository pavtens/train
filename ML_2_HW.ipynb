{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM   ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "501  0.06263  0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527  0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076  0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959  0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741  0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_boston()\n",
    "X = pd.DataFrame(dataset.data)\n",
    "X.columns = dataset.feature_names\n",
    "y = dataset.target\n",
    "\n",
    "X.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Разделите выборку на обучающую и тестовую в отношении 80%/20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (102, 13), (404,), (102,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Обучите стандартную регрессию, а также Ridge и  Lasso и параметрами по умолчанию и выведите их R2 на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6687594935356278"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.666222167016852"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred = ridge.predict(X_test)\n",
    "r2_ridge = r2_score(y_test, y_pred)\n",
    "r2_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 7.83 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6671453631686304"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lasso = Lasso(alpha=1)\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred = lasso.predict(X_test)\n",
    "r2_lasso = r2_score(y_test, y_pred)\n",
    "r2_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Для Ridge и Lasso подберите коэффициент регуляризации(используйте GridSearchCV, RidgeCV, LassoCV) в пределах от $10^{-5}$ до $10^5$ (по степеням 10). Посчитайте R2 на тестовой выборке по лучшим моделям и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1e-05}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv_lasso = GridSearchCV(lasso, {'alpha': [10**i for i in range(-5,6)]}, cv=5)\n",
    "grid_search_cv_lasso.fit(X_train, y_train)\n",
    "grid_search_cv_lasso.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1e-05}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv_ridge = GridSearchCV(ridge, {'alpha': [10**i for i in range(-5,6)]}, cv=5)\n",
    "grid_search_cv_ridge.fit(X_train, y_train)\n",
    "grid_search_cv_ridge.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6687598638315153\n",
      "0.6687594856409733\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=10**-5)\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred = lasso.predict(X_test)\n",
    "r2_lasso_cv = r2_score(y_test, y_pred)\n",
    "r2_lasso_cv\n",
    "\n",
    "ridge = Ridge(alpha=10**-5)\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred = ridge.predict(X_test)\n",
    "r2_ridge_cv = r2_score(y_test, y_pred)\n",
    "r2_ridge_cv\n",
    "\n",
    "print(r2_lasso_cv, r2_ridge_cv, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6687598638315153"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_cv = LassoCV(alphas=[10**i for i in range(-5,6)], cv=5).fit(X_train, y_train)\n",
    "y_pred = lasso_cv.predict(X_test)\n",
    "r2_lasso_cv = r2_score(y_test, y_pred)\n",
    "r2_lasso_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6687594856409733"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv = RidgeCV(alphas=[10**i for i in range(-5,6)], cv=5).fit(X_train, y_train)\n",
    "y_pred = ridge_cv.predict(X_test)\n",
    "r2_ridge_cv = r2_score(y_test, y_pred)\n",
    "r2_ridge_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16145006628849323\n",
      "0.2537318624121321\n"
     ]
    }
   ],
   "source": [
    "# R2 вырос на десятые процента\n",
    "print((r2_lasso_cv-r2_lasso)*100, (r2_ridge_cv-r2_ridge)*100, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha_per_target': False,\n",
       " 'alphas': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000],\n",
       " 'cv': 5,\n",
       " 'fit_intercept': True,\n",
       " 'gcv_mode': None,\n",
       " 'normalize': 'deprecated',\n",
       " 'scoring': None,\n",
       " 'store_cv_values': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Непонятно, в связи с чем get_params не подсвечивает лучший alpha\n",
    "ridge_cv = RidgeCV(alphas=[10**i for i in range(-5,6)], cv=5).fit(X_train, y_train)\n",
    "ridge_cv.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Проведите масштабирование выборки(используйте Pipeline, StandardScaler, MinMaxScaler), посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.668759038334717"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('scaler',StandardScaler()), ('clf', Lasso(alpha=10**-5))])\n",
    "pipeline.fit(X_train, y_train)\n",
    "r2_lasso_scaler = pipeline.score(X_test, y_test)\n",
    "r2_lasso_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6687594905710064"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('scaler',StandardScaler()), ('clf', Ridge(alpha=10**-5))])\n",
    "pipeline.fit(X_train, y_train)\n",
    "r2_ridge_scaler = pipeline.score(X_test, y_test)\n",
    "r2_ridge_scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.254967983623018e-05\n",
      "4.930033048466953e-07\n"
     ]
    }
   ],
   "source": [
    "# R2 существенно не изменился\n",
    "print((r2_lasso_scaler-r2_lasso_cv)*100, (r2_ridge_scaler-r2_ridge_cv)*100, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6687605073677362"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Нормализация (0,1) привела к несущественному росту R2 к стандартизации\n",
    "pipeline = Pipeline([('scaler', MinMaxScaler()), ('clf', Lasso(alpha=10**-5))])\n",
    "pipeline.fit(X_train, y_train)\n",
    "r2_lasso_scaler = pipeline.score(X_test, y_test)\n",
    "r2_lasso_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6687596289762525"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('scaler',MinMaxScaler()), ('clf', Ridge(alpha=10**-5))])\n",
    "pipeline.fit(X_train, y_train)\n",
    "r2_ridge_scaler = pipeline.score(X_test, y_test)\n",
    "r2_ridge_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>-0.413229</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>0.439316</td>\n",
       "      <td>0.018673</td>\n",
       "      <td>-0.625796</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.387217</td>\n",
       "      <td>-0.418147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>-0.415249</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>-0.234548</td>\n",
       "      <td>0.288933</td>\n",
       "      <td>-0.716639</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.500850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>-0.413447</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>0.984960</td>\n",
       "      <td>0.797449</td>\n",
       "      <td>-0.773684</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.983048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>-0.407764</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>0.725672</td>\n",
       "      <td>0.736996</td>\n",
       "      <td>-0.668437</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.403225</td>\n",
       "      <td>-0.865302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>-0.415000</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>-0.362767</td>\n",
       "      <td>0.434732</td>\n",
       "      <td>-0.613246</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.669058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "501 -0.413229 -0.487722  0.115738 -0.272599  0.158124  0.439316  0.018673   \n",
       "502 -0.415249 -0.487722  0.115738 -0.272599  0.158124 -0.234548  0.288933   \n",
       "503 -0.413447 -0.487722  0.115738 -0.272599  0.158124  0.984960  0.797449   \n",
       "504 -0.407764 -0.487722  0.115738 -0.272599  0.158124  0.725672  0.736996   \n",
       "505 -0.415000 -0.487722  0.115738 -0.272599  0.158124 -0.362767  0.434732   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "501 -0.625796 -0.982843 -0.803212  1.176466  0.387217 -0.418147  \n",
       "502 -0.716639 -0.982843 -0.803212  1.176466  0.441052 -0.500850  \n",
       "503 -0.773684 -0.982843 -0.803212  1.176466  0.441052 -0.983048  \n",
       "504 -0.668437 -0.982843 -0.803212  1.176466  0.403225 -0.865302  \n",
       "505 -0.613246 -0.982843 -0.803212  1.176466  0.441052 -0.669058  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_0 = pd.DataFrame(scaler.transform(X))\n",
    "\n",
    "X_0.columns = dataset.feature_names\n",
    "X_0.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15968566],\n",
       "       [-0.10152429],\n",
       "       [ 1.32424667],\n",
       "       [ 1.18275795],\n",
       "       [ 1.48750288]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_0 = y\n",
    "y_0 = y_0.reshape(-1,1)\n",
    "scaler.fit(y_0)\n",
    "y_0 = scaler.transform(y_0)\n",
    "\n",
    "y_0[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (102, 13), (404, 1), (102, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_0_train, X_0_test, y_0_train, y_0_test = train_test_split(X_0, y_0, test_size=0.2, random_state=42)\n",
    "X_0_train.shape, X_0_test.shape, y_0_train.shape, y_0_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6684401592810274"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вывод: незначительно хуже, чем без стандартизации\n",
    "ridge_cv = RidgeCV(alphas=[10**i for i in range(-5,6)], cv=5).fit(X_0_train, y_0_train)\n",
    "\n",
    "r2_ridge_cv = ridge_cv.score(X_0_test, y_0_test)\n",
    "r2_ridge_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6687590128437058\n",
      "0.6684401592810272\n"
     ]
    }
   ],
   "source": [
    "# Можно было не нормализовать y (несущественно на данной выборке?)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_0 = pd.DataFrame(scaler.transform(X))\n",
    "X_0.columns = dataset.feature_names\n",
    "\n",
    "X_0_train, X_0_test, y_train, y_test = train_test_split(X_0, y, test_size=0.2, random_state=42)\n",
    "X_0_train.shape, X_0_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "ridge_cv = RidgeCV(alphas=[10**i for i in range(-5,6)], cv=5).fit(X_0_train, y_train)\n",
    "r2_ridge_cv = ridge_cv.score(X_0_test, y_test)\n",
    "\n",
    "lasso_cv = LassoCV(alphas=[10**i for i in range(-5,6)], cv=5).fit(X_0_train, y_train)\n",
    "r2_lasso_cv = lasso_cv.score(X_0_test, y_test)\n",
    "\n",
    "print(r2_lasso_cv, r2_ridge_cv, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.668760771409485\n",
      "0.6702995459264811\n"
     ]
    }
   ],
   "source": [
    "# Вывод: нормализация (0,1) приводит к росту R2 на 0,15% при l2 регуляризации, незначительное изменение при l1 регуляризации\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_0 = pd.DataFrame(scaler.transform(X))\n",
    "X_0.columns = dataset.feature_names\n",
    "X_0.tail()\n",
    "\n",
    "X_0_train, X_0_test, y_0_train, y_0_test = train_test_split(X_0, y, test_size=0.2, random_state=42)\n",
    "X_0_train.shape, X_0_test.shape, y_0_train.shape, y_0_test.shape\n",
    "\n",
    "ridge_cv = RidgeCV(alphas=[10**i for i in range(-5,6)], cv=5).fit(X_0_train, y_0_train)\n",
    "r2_ridge_cv = ridge_cv.score(X_0_test, y_0_test)\n",
    "\n",
    "lasso_cv = LassoCV(alphas=[10**i for i in range(-5,6)], cv=5).fit(X_0_train, y_0_train)\n",
    "r2_lasso_cv = lasso_cv.score(X_0_test, y_0_test)\n",
    "\n",
    "print(r2_lasso_cv, r2_ridge_cv, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6700309977617651"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Лаконичный код с RidgeCV/LassoCV , если не требуется выводить df / target с масш.значениями\n",
    "pipeline = Pipeline([('scaler', MinMaxScaler()), ('clf', RidgeCV(alphas=[10**i for i in range(-5,6)], cv=5))])\n",
    "pipeline.fit(X_train, y_train)\n",
    "r2_ridge_scaler = pipeline.score(X_test, y_test)\n",
    "r2_ridge_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Добавьте попарные произведения признаков и их квадраты (используйте PolynomialFeatures) на масштабированных признаках, посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386831</td>\n",
       "      <td>0.619467</td>\n",
       "      <td>0.889804</td>\n",
       "      <td>0.114514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026936</td>\n",
       "      <td>0.146662</td>\n",
       "      <td>0.162694</td>\n",
       "      <td>0.021512</td>\n",
       "      <td>0.798551</td>\n",
       "      <td>0.885843</td>\n",
       "      <td>0.117127</td>\n",
       "      <td>0.982677</td>\n",
       "      <td>0.129930</td>\n",
       "      <td>0.017180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386831</td>\n",
       "      <td>0.473079</td>\n",
       "      <td>0.802266</td>\n",
       "      <td>0.125072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026936</td>\n",
       "      <td>0.146662</td>\n",
       "      <td>0.164122</td>\n",
       "      <td>0.027852</td>\n",
       "      <td>0.798551</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.151649</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.169702</td>\n",
       "      <td>0.028799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1    2         3    4         5         6         7    \\\n",
       "504  1.0  0.001161  0.0  0.420455  0.0  0.386831  0.619467  0.889804   \n",
       "505  1.0  0.000462  0.0  0.420455  0.0  0.386831  0.473079  0.802266   \n",
       "\n",
       "          8    9    ...       95        96        97        98        99   \\\n",
       "504  0.114514  0.0  ...  0.026936  0.146662  0.162694  0.021512  0.798551   \n",
       "505  0.125072  0.0  ...  0.026936  0.146662  0.164122  0.027852  0.798551   \n",
       "\n",
       "          100       101       102       103       104  \n",
       "504  0.885843  0.117127  0.982677  0.129930  0.017180  \n",
       "505  0.893617  0.151649  1.000000  0.169702  0.028799  \n",
       "\n",
       "[2 rows x 105 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "X_1 = poly.fit_transform(X_0)\n",
    "X_1 = pd.DataFrame(X_1)\n",
    "\n",
    "X_1.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.231340122170646\n",
      "18.077462670471036\n"
     ]
    }
   ],
   "source": [
    "#Вывод: R2 вырос на 18,1-18,2%\n",
    "\n",
    "X_1_train, X_1_test, y_1_train, y_1_test = train_test_split(X_1, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lasso_cv = RidgeCV(alphas=[10**i for i in range(-5,6)], cv=5)\n",
    "lasso_cv.fit(X_1_train, y_1_train)\n",
    "r2_lasso_scaler_1 = lasso_cv.score(X_1_test, y_1_test)\n",
    "\n",
    "ridge_cv = RidgeCV(alphas=[10**i for i in range(-5,6)], cv=5)\n",
    "ridge_cv.fit(X_1_train, y_1_train)\n",
    "r2_ridge_scaler_1 = ridge_cv.score(X_1_test, y_1_test)\n",
    "\n",
    "print(100*(r2_lasso_scaler_1-r2_lasso_cv), 100*(r2_ridge_scaler_1-r2_ridge_cv), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.246722741713711, tolerance: 2.8821090464396293\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 716.793121638431, tolerance: 2.8821090464396293\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 763.7300474513919, tolerance: 2.8821090464396293\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 745.4537354076956, tolerance: 2.8821090464396293\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.808566254732796, tolerance: 2.764448730650155\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 769.4143954761016, tolerance: 2.764448730650155\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 768.7347892587749, tolerance: 2.764448730650155\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 776.5877687316574, tolerance: 2.764448730650155\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 850.7103764062363, tolerance: 2.710494922600619\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 890.386180979786, tolerance: 2.710494922600619\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 870.1936984467925, tolerance: 2.710494922600619\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 461.1982143026121, tolerance: 2.7297569226006195\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 779.798200048964, tolerance: 2.7297569226006195\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 786.2785889817224, tolerance: 2.7297569226006195\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15.976478762306215, tolerance: 2.947695024691358\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 464.01181317552687, tolerance: 2.947695024691358\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 789.583757609484, tolerance: 2.947695024691358\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 808.6471231250979, tolerance: 2.947695024691358\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.650e+02, tolerance: 3.510e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.029739664234565\n",
      "17.97634963023933\n",
      "CPU times: total: 547 ms\n",
      "Wall time: 652 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Вариант лаконичного кода\n",
    "# Разница в R2 меньше на 1% по l1 регуляризации в отличии то того, когда масштабируем и добавляем полиномы вручную,\n",
    "# (в чем причина?)\n",
    "\n",
    "pipeline = Pipeline([('transform_1', MinMaxScaler()), ('transform_2', PolynomialFeatures()), \n",
    "('clf', LassoCV(alphas=[10**i for i in range(-5,6)], cv=5))])\n",
    "pipeline.fit(X_train, y_train)\n",
    "r2_lasso_scaler_2 = pipeline.score(X_test, y_test)\n",
    "\n",
    "pipeline = Pipeline([('transform_1', MinMaxScaler()), ('transform_2', PolynomialFeatures()), \n",
    "('clf', RidgeCV(alphas=[10**i for i in range(-5,6)], cv=5))])\n",
    "pipeline.fit(X_train, y_train)\n",
    "r2_ridge_scaler_2 = pipeline.score(X_test, y_test)\n",
    "\n",
    "print(100*(r2_lasso_scaler_2-r2_lasso_cv), 100*(r2_ridge_scaler_2-r2_ridge_cv), sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Подберите наилучшую модель (используйте Pipeline, GridSearchSCV) подбирая тип регуляризации (L1,L2), коэффициент регуляризации, метод масштабирования и степень полинома в PolynomialFeatures. Выведите итоговые параметры и результат R2. Напишите как изменился R2 по сравнению с предыдущими экспериментами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('transform_1', MinMaxScaler()), ('transform_2', PolynomialFeatures()),\n",
    "('clf', Ridge())])\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        'transform_1': (MinMaxScaler(),),\n",
    "        'transform_2__degree': range(2,4),\n",
    "        \n",
    "        'clf': (Ridge(),),\n",
    "        'clf__alpha': [10**i for i in range(-5,6)],\n",
    "    }, {\n",
    "        'transform_1': (MinMaxScaler(),),\n",
    "        'transform_2__degree': range(2,4),\n",
    "        \n",
    "        'clf': (Lasso(),),\n",
    "        'clf__alpha': [10**i for i in range(-5,6)]\n",
    "    }, {\n",
    "        'transform_1': (StandardScaler(),),\n",
    "        'transform_2__degree': range(2,4),\n",
    "        \n",
    "        'clf': (Ridge(),),\n",
    "        'clf__alpha': [10**i for i in range(-5,6)],\n",
    "    }, {\n",
    "        'transform_1': (StandardScaler(),),\n",
    "        'transform_2__degree': range(2,4),\n",
    "        \n",
    "        'clf': (Lasso(),),\n",
    "        'clf__alpha': [10**i for i in range(-5,6)]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.989e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.289e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.230e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.135e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.594e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.097e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.527e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.307e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.489e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.601e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.286e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.485e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.348e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.131e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.478e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.332e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.010e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.578e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.287e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.336e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.238e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.172e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.963e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.592e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.836e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.148e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.740e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.746e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.345e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.485e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.002e+01, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.484e+00, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.759e+01, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.238e+01, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.810e+01, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.528e+01, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e+01, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.972e+01, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+01, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.151e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.188e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.129e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.545e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.804e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.113e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.149e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.813e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.525e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.789e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.161e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.436e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.653e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.004e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.094e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.062e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.555e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.164e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.033e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.302e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.154e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.451e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.553e+00, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.056e+00, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.331e+01, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.344e+00, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.517e+00, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.625e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.018e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.479e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.448e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.805e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.040e+00, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.743e+02, tolerance: 3.510e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf': Lasso(alpha=0.001),\n",
       " 'clf__alpha': 0.001,\n",
       " 'transform_1': MinMaxScaler(),\n",
       " 'transform_2__degree': 3}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipeline, parameters, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8449734005131505\n",
      "0.8510741726311915\n",
      "0.8510741726311915\n"
     ]
    }
   ],
   "source": [
    "# Результат ниже на 0,6% чем наиболее высокие из ранее найденных R2 \n",
    "best_clf = grid_search.best_estimator_\n",
    "best_clf.get_params()\n",
    "score = best_clf.score(X_test, y_test)\n",
    "\n",
    "r2_ridge_scaler_1 = ridge_cv.score(X_1_test, y_1_test)\n",
    "print(score, r2_lasso_scaler_1, r2_ridge_scaler_1, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8588479918651002"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Результат > 85% (самый высокий) был достингут применением LassoCV/RidgeCV\n",
    "#  на стандартный полином (2) и масштабирование (0,1), проверим ниже на Ridge - R2 выше 85%.\n",
    "#  Есть вероятность, что пайплайн выше отработал некорректно из-за ошибки.\n",
    "pipeline = Pipeline([('transform_1', MinMaxScaler()), ('transform_2', PolynomialFeatures(3)), \n",
    "('clf', RidgeCV(alphas=[10**i for i in range(-5,6)]))])\n",
    "pipeline.fit(X_train, y_train)\n",
    "r2 = pipeline.score(X_test, y_test)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8588479918651302"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Поскольку ошибка возникает на lasso, возьмем только ridge\n",
    "#  R2 уже выше остальных (86%), адекватный результат\n",
    "pipeline = Pipeline([('transform_1', MinMaxScaler()), ('transform_2', PolynomialFeatures()),\n",
    "('clf', Ridge())])\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        'transform_1': (MinMaxScaler(),),\n",
    "        'transform_2__degree': range(2,4),\n",
    "        \n",
    "        'clf': (Ridge(),),\n",
    "        'clf__alpha': [10**i for i in range(-5,6)],\n",
    "    }, {\n",
    "        'transform_1': (StandardScaler(),),\n",
    "        'transform_2__degree': range(2,4),\n",
    "        \n",
    "        'clf': (Ridge(),),\n",
    "        'clf__alpha': [10**i for i in range(-5,6)],\n",
    "    }\n",
    "]\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_clf = grid_search.best_estimator_\n",
    "score = best_clf.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('transform_1', MinMaxScaler()),\n",
       "  ('transform_2', PolynomialFeatures(degree=3)),\n",
       "  ('clf', Ridge(alpha=0.1))],\n",
       " 'verbose': False,\n",
       " 'transform_1': MinMaxScaler(),\n",
       " 'transform_2': PolynomialFeatures(degree=3),\n",
       " 'clf': Ridge(alpha=0.1),\n",
       " 'transform_1__clip': False,\n",
       " 'transform_1__copy': True,\n",
       " 'transform_1__feature_range': (0, 1),\n",
       " 'transform_2__degree': 3,\n",
       " 'transform_2__include_bias': True,\n",
       " 'transform_2__interaction_only': False,\n",
       " 'transform_2__order': 'C',\n",
       " 'clf__alpha': 0.1,\n",
       " 'clf__copy_X': True,\n",
       " 'clf__fit_intercept': True,\n",
       " 'clf__max_iter': None,\n",
       " 'clf__normalize': 'deprecated',\n",
       " 'clf__positive': False,\n",
       " 'clf__random_state': None,\n",
       " 'clf__solver': 'auto',\n",
       " 'clf__tol': 0.001}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.989e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.289e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.230e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.135e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.594e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.097e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.527e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.307e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.489e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.601e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.151e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.188e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.129e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.545e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.804e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.286e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.485e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.348e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.131e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.478e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.332e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.010e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.578e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.287e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.336e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.113e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.149e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.813e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.525e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.789e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.161e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.436e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.238e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.172e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.963e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.592e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.836e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.148e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.740e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.746e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.345e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.485e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.653e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.004e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.094e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.062e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.555e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.164e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.033e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.302e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.154e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.451e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.002e+01, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.484e+00, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.759e+01, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.238e+01, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.810e+01, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.528e+01, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e+01, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.972e+01, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+01, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.553e+00, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.056e+00, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.331e+01, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.344e+00, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.517e+00, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.625e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.018e+02, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.479e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.448e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.805e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.040e+00, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.743e+02, tolerance: 3.510e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8449734005131505"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Более лаконичный код, все еще предполож-но некорректная работа с l1 регуляризацией, почему?\n",
    "pipeline = Pipeline([('transform_1', MinMaxScaler()), ('transform_2', PolynomialFeatures()),\n",
    "('clf', Ridge())])\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        'transform_1': (MinMaxScaler(),StandardScaler()),\n",
    "        'transform_2__degree': range(2,4),\n",
    "        \n",
    "        'clf': (Ridge(),Lasso()),\n",
    "        'clf__alpha': [10**i for i in range(-5,6)],\n",
    "    }\n",
    "]\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_clf = grid_search.best_estimator_\n",
    "score = best_clf.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/adult-all.csv'\n",
    "data = pd.read_csv(link, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>?</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0             1       2          3   4                   5   \\\n",
       "48837  39       Private  215419  Bachelors  13            Divorced   \n",
       "48838  64             ?  321403    HS-grad   9             Widowed   \n",
       "48839  38       Private  374983  Bachelors  13  Married-civ-spouse   \n",
       "48840  44       Private   83891  Bachelors  13            Divorced   \n",
       "48841  35  Self-emp-inc  182148  Bachelors  13  Married-civ-spouse   \n",
       "\n",
       "                    6               7                   8       9     10  11  \\\n",
       "48837   Prof-specialty   Not-in-family               White  Female     0   0   \n",
       "48838                ?  Other-relative               Black    Male     0   0   \n",
       "48839   Prof-specialty         Husband               White    Male     0   0   \n",
       "48840     Adm-clerical       Own-child  Asian-Pac-Islander    Male  5455   0   \n",
       "48841  Exec-managerial         Husband               White    Male     0   0   \n",
       "\n",
       "       12             13     14  \n",
       "48837  36  United-States  <=50K  \n",
       "48838  40  United-States  <=50K  \n",
       "48839  50  United-States  <=50K  \n",
       "48840  40  United-States  <=50K  \n",
       "48841  60  United-States   >50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Разделите выборку на признаки и целевую переменную(колонка со зачениями {<=50K,>50K}). Замените целевую переменную на числовые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brigh\\AppData\\Local\\Temp\\ipykernel_2544\\2374188803.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[y=='<=50K'] = 0\n",
      "C:\\Users\\brigh\\AppData\\Local\\Temp\\ipykernel_2544\\2374188803.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[y=='>50K'] = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[y=='<=50K'] = 0\n",
    "y[y=='>50K'] = 1\n",
    "y=y.astype('int')\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Выясните, присутствуют ли в данных пропуски. Заполните их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NaN отсутствуют\n",
    "X[X==np.nan].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "5         0\n",
       "6         0\n",
       "7         0\n",
       "8         0\n",
       "9         0\n",
       "10    44807\n",
       "11    46560\n",
       "12        0\n",
       "13        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заемним нули для тренировки\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X_test = X\n",
    "\n",
    "imp = SimpleImputer(missing_values=0, strategy='most_frequent')\n",
    "imp.fit(X_test.iloc[:,10:12])\n",
    "X_test.iloc[:,10:12] = imp.transform(X_test.iloc[:,10:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[X_test==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39, 'State-gov', 77516, ..., 1902, 40, 'United-States'],\n",
       "       [50, 'Self-emp-not-inc', 83311, ..., 1902, 13, 'United-States'],\n",
       "       [38, 'Private', 215646, ..., 1902, 40, 'United-States'],\n",
       "       ...,\n",
       "       [38, 'Private', 374983, ..., 1902, 50, 'United-States'],\n",
       "       [44, 'Private', 83891, ..., 1902, 40, 'United-States'],\n",
       "       [35, 'Self-emp-inc', 182148, ..., 1902, 60, 'United-States']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Поскольку требовалось заменить пропуски а не нули, далее работаем с исходным X\n",
    "imp = SimpleImputer(strategy='most_frequent')\n",
    "imp.fit(X)\n",
    "X = imp.transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>1902</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>?</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>1902</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>1902</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>1902</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>1902</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0             1       2          3   4                   5   \\\n",
       "48837  39       Private  215419  Bachelors  13            Divorced   \n",
       "48838  64             ?  321403    HS-grad   9             Widowed   \n",
       "48839  38       Private  374983  Bachelors  13  Married-civ-spouse   \n",
       "48840  44       Private   83891  Bachelors  13            Divorced   \n",
       "48841  35  Self-emp-inc  182148  Bachelors  13  Married-civ-spouse   \n",
       "\n",
       "                    6               7                   8       9      10  \\\n",
       "48837   Prof-specialty   Not-in-family               White  Female  15024   \n",
       "48838                ?  Other-relative               Black    Male  15024   \n",
       "48839   Prof-specialty         Husband               White    Male  15024   \n",
       "48840     Adm-clerical       Own-child  Asian-Pac-Islander    Male   5455   \n",
       "48841  Exec-managerial         Husband               White    Male  15024   \n",
       "\n",
       "         11  12             13  \n",
       "48837  1902  36  United-States  \n",
       "48838  1902  40  United-States  \n",
       "48839  1902  50  United-States  \n",
       "48840  1902  40  United-States  \n",
       "48841  1902  60  United-States  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(X)\n",
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Странно что датафреймы не идентичны, тк проверка isna / ==np.nan показала что\n",
    "#  пропусков нет, далее станет понятно что слетели типы данных колонок\n",
    "X.equals(data.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Выберите колонки с числовыми и категориальными переменными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Int64\n",
       "1     string\n",
       "2      Int64\n",
       "3     string\n",
       "4      Int64\n",
       "5     string\n",
       "6     string\n",
       "7     string\n",
       "8     string\n",
       "9     string\n",
       "10     Int64\n",
       "11     Int64\n",
       "12     Int64\n",
       "13    string\n",
       "dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Теперь понтяно почему датафреймы не были идентичны. Слетел тип колонок после SimpleImputer\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Int64\n",
       "1     string\n",
       "2      Int64\n",
       "3     string\n",
       "4      Int64\n",
       "5     string\n",
       "6     string\n",
       "7     string\n",
       "8     string\n",
       "9     string\n",
       "10     Int64\n",
       "11     Int64\n",
       "12     Int64\n",
       "13    string\n",
       "dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.convert_dtypes()\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 2, 4, 10, 11, 12], dtype='int64')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num = X.select_dtypes('number')\n",
    "X_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1, 3, 5, 6, 7, 8, 9, 13], dtype='int64')"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_obj = X.select_dtypes(exclude='number')\n",
    "X_obj.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Создайте пайплайн по обработке колонок(используйте OneHotEncoder,MinMaxScaler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn2pmml import PMMLPipeline\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import precision_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 7)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 29)\\t1.0\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 27)\\t1.0\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 25)\\t1.0\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 10)\\t1.0\\n  (0, 27)\\t1.0\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 27)\\t1.0\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0    (0, 7)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 29)\\t1.0\\...\n",
       "1    (0, 6)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 27)\\t1.0\\...\n",
       "2    (0, 4)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 25)\\t1.0\\...\n",
       "3    (0, 4)\\t1.0\\n  (0, 10)\\t1.0\\n  (0, 27)\\t1.0\\...\n",
       "4    (0, 4)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 27)\\t1.0\\..."
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ColumnTransformer и mapper применяют OneHotEncoder ко всем колонкам, формируя из поданных фичей одну в виде string\n",
    "#  Ответ был найедн под конец домашки, необходимо оборачивать масшт-е функции в ColTransformer\n",
    "\n",
    "trf1 = ColumnTransformer(transformers =[\n",
    "    ('cat', OneHotEncoder(), [1, 3, 5, 6, 7, 8, 9, 13]),\n",
    "    ('num', MinMaxScaler(), [0, 2, 4, 10, 11, 12]),\n",
    "      \n",
    "])\n",
    "\n",
    "first_step = trf1.fit_transform(X)\n",
    "pd.DataFrame(first_step).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 22)\\t1.0\\n  (0, 3535)\\t1.0\\n  (0, 28609)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 33)\\t1.0\\n  (0, 3862)\\t1.0\\n  (0, 28609)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 21)\\t1.0\\n  (0, 18416)\\t1.0\\n  (0, 28605...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 36)\\t1.0\\n  (0, 20069)\\t1.0\\n  (0, 28603...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 11)\\t1.0\\n  (0, 25479)\\t1.0\\n  (0, 28609...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0    (0, 22)\\t1.0\\n  (0, 3535)\\t1.0\\n  (0, 28609)...\n",
       "1    (0, 33)\\t1.0\\n  (0, 3862)\\t1.0\\n  (0, 28609)...\n",
       "2    (0, 21)\\t1.0\\n  (0, 18416)\\t1.0\\n  (0, 28605...\n",
       "3    (0, 36)\\t1.0\\n  (0, 20069)\\t1.0\\n  (0, 28603...\n",
       "4    (0, 11)\\t1.0\\n  (0, 25479)\\t1.0\\n  (0, 28609..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mapper = DataFrameMapper(\n",
    "    [(d, LabelEncoder()) for d in [0, 2, 4, 10, 11, 12]]\n",
    ")\n",
    "\n",
    "lm = PMMLPipeline([(\"mapper\", mapper),\n",
    "                   (\"regressor\", OneHotEncoder())])\n",
    "lm.fit(X, y)\n",
    "Df = pd.DataFrame(lm.transform(X))\n",
    "Df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9    ...  92   93   94   \\\n",
       "48837  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "48838  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "48839  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "48840  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "48841  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "       95   96   97   98   99   100  101  \n",
       "48837  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "48838  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "48839  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "48840  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "48841  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# В таком случае работаем вручную с категор. и количеств. признаками\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(X_obj)\n",
    "\n",
    "a = enc.transform(X_obj).toarray()\n",
    "b = pd.DataFrame(a.tolist())\n",
    "b.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.137428</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>0.643836</td>\n",
       "      <td>0.209130</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.245379</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>0.369863</td>\n",
       "      <td>0.048444</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.053471</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>0.246575</td>\n",
       "      <td>0.114919</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.602041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5\n",
       "48837  0.301370  0.137428  0.800000  0.149272  0.415853  0.357143\n",
       "48838  0.643836  0.209130  0.533333  0.149272  0.415853  0.397959\n",
       "48839  0.287671  0.245379  0.800000  0.149272  0.415853  0.500000\n",
       "48840  0.369863  0.048444  0.800000  0.053471  0.415853  0.397959\n",
       "48841  0.246575  0.114919  0.800000  0.149272  0.415853  0.602041"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = MinMaxScaler()\n",
    "enc.fit(X_num)\n",
    "\n",
    "a = enc.transform(X_num)\n",
    "c = pd.DataFrame(a)\n",
    "c.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.137428</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643836</td>\n",
       "      <td>0.209130</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.245379</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369863</td>\n",
       "      <td>0.048444</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.053471</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246575</td>\n",
       "      <td>0.114919</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.602041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9    ...  98   99   100  \\\n",
       "48837  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0   \n",
       "48838  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0   \n",
       "48839  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0   \n",
       "48840  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0   \n",
       "48841  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0   \n",
       "\n",
       "       101       102       103       104       105       106       107  \n",
       "48837  0.0  0.301370  0.137428  0.800000  0.149272  0.415853  0.357143  \n",
       "48838  0.0  0.643836  0.209130  0.533333  0.149272  0.415853  0.397959  \n",
       "48839  0.0  0.287671  0.245379  0.800000  0.149272  0.415853  0.500000  \n",
       "48840  0.0  0.369863  0.048444  0.800000  0.053471  0.415853  0.397959  \n",
       "48841  0.0  0.246575  0.114919  0.800000  0.149272  0.415853  0.602041  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Итоговый дф\n",
    "Df = pd.concat([b, c], axis=1)\n",
    "Df.columns = [i for i in range(0,108)]\n",
    "Df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.044131</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.020624</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.048052</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.122449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.137581</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.150486</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.220635</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  98   99   100  101  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "        102       103       104       105       106       107  \n",
       "0  0.301370  0.044131  0.800000  0.020624  0.415853  0.397959  \n",
       "1  0.452055  0.048052  0.800000  0.149272  0.415853  0.122449  \n",
       "2  0.287671  0.137581  0.533333  0.149272  0.415853  0.397959  \n",
       "3  0.493151  0.150486  0.400000  0.149272  0.415853  0.397959  \n",
       "4  0.150685  0.220635  0.800000  0.149272  0.415853  0.397959  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Для кор.работы с OneHot в ColTransformer необходимо выводить результаты в array, а не в sparse matrix\n",
    "trf2 = ColumnTransformer(transformers =[\n",
    "    ('cat', OneHotEncoder(), [1, 3, 5, 6, 7, 8, 9, 13]),\n",
    "    ('num', MinMaxScaler(), [0, 2, 4, 10, 11, 12]),\n",
    "      \n",
    "], sparse_threshold=0)\n",
    "\n",
    "first_step = trf2.fit_transform(X)\n",
    "pd.DataFrame(first_step).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.044131</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.020624</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.048052</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.122449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.137581</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.150486</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.220635</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  98   99   100  101  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "        102       103       104       105       106       107  \n",
       "0  0.301370  0.044131  0.800000  0.020624  0.415853  0.397959  \n",
       "1  0.452055  0.048052  0.800000  0.149272  0.415853  0.122449  \n",
       "2  0.287671  0.137581  0.533333  0.149272  0.415853  0.397959  \n",
       "3  0.493151  0.150486  0.400000  0.149272  0.415853  0.397959  \n",
       "4  0.150685  0.220635  0.800000  0.149272  0.415853  0.397959  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Еще одина вариант с ColTransformer\n",
    "\n",
    "trf2 = ColumnTransformer(transformers =[\n",
    "    ('cat', OneHotEncoder(sparse=False), [1, 3, 5, 6, 7, 8, 9, 13]),\n",
    "    ('num', MinMaxScaler(), [0, 2, 4, 10, 11, 12]),\n",
    "      \n",
    "])\n",
    "\n",
    "first_step = trf2.fit_transform(X)\n",
    "pd.DataFrame(first_step).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.044131</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.020624</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.048052</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.122449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.137581</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.150486</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.220635</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  98   99   100  101  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "        102       103       104       105       106       107  \n",
       "0  0.301370  0.044131  0.800000  0.020624  0.415853  0.397959  \n",
       "1  0.452055  0.048052  0.800000  0.149272  0.415853  0.122449  \n",
       "2  0.287671  0.137581  0.533333  0.149272  0.415853  0.397959  \n",
       "3  0.493151  0.150486  0.400000  0.149272  0.415853  0.397959  \n",
       "4  0.150685  0.220635  0.800000  0.149272  0.415853  0.397959  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipel = Pipeline([\n",
    "    ('cat', trf2), ('clf', SVC())\n",
    "      \n",
    "])\n",
    "\n",
    "first_step = trf2.fit_transform(X)\n",
    "pd.DataFrame(first_step).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.044131</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.020624</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.048052</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.122449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.137581</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.150486</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.220635</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  98   99   100  101  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "        102       103       104       105       106       107  \n",
       "0  0.301370  0.044131  0.800000  0.020624  0.415853  0.397959  \n",
       "1  0.452055  0.048052  0.800000  0.149272  0.415853  0.122449  \n",
       "2  0.287671  0.137581  0.533333  0.149272  0.415853  0.397959  \n",
       "3  0.493151  0.150486  0.400000  0.149272  0.415853  0.397959  \n",
       "4  0.150685  0.220635  0.800000  0.149272  0.415853  0.397959  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipel_1 = Pipeline([\n",
    "    ('cat', OneHotEncoder(sparse=False), [1, 3, 5, 6, 7, 8, 9, 13]),\n",
    "    ('num', MinMaxScaler(), [0, 2, 4, 10, 11, 12]), ('clf', SVC())\n",
    "      \n",
    "])\n",
    "\n",
    "first_step = trf2.fit_transform(X)\n",
    "Dg = pd.DataFrame(first_step)\n",
    "Dg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('cat',\n",
       "   ColumnTransformer(transformers=[('cat', OneHotEncoder(sparse=False),\n",
       "                                    [1, 3, 5, 6, 7, 8, 9, 13]),\n",
       "                                   ('num', MinMaxScaler(), [0, 2, 4, 10, 11, 12])])),\n",
       "  ('clf', SVC())],\n",
       " 'verbose': False,\n",
       " 'cat': ColumnTransformer(transformers=[('cat', OneHotEncoder(sparse=False),\n",
       "                                  [1, 3, 5, 6, 7, 8, 9, 13]),\n",
       "                                 ('num', MinMaxScaler(), [0, 2, 4, 10, 11, 12])]),\n",
       " 'clf': SVC(),\n",
       " 'cat__n_jobs': None,\n",
       " 'cat__remainder': 'drop',\n",
       " 'cat__sparse_threshold': 0.3,\n",
       " 'cat__transformer_weights': None,\n",
       " 'cat__transformers': [('cat',\n",
       "   OneHotEncoder(sparse=False),\n",
       "   [1, 3, 5, 6, 7, 8, 9, 13]),\n",
       "  ('num', MinMaxScaler(), [0, 2, 4, 10, 11, 12])],\n",
       " 'cat__verbose': False,\n",
       " 'cat__verbose_feature_names_out': True,\n",
       " 'cat__cat': OneHotEncoder(sparse=False),\n",
       " 'cat__num': MinMaxScaler(),\n",
       " 'cat__cat__categories': 'auto',\n",
       " 'cat__cat__drop': None,\n",
       " 'cat__cat__dtype': numpy.float64,\n",
       " 'cat__cat__handle_unknown': 'error',\n",
       " 'cat__cat__max_categories': None,\n",
       " 'cat__cat__min_frequency': None,\n",
       " 'cat__cat__sparse': False,\n",
       " 'cat__num__clip': False,\n",
       " 'cat__num__copy': True,\n",
       " 'cat__num__feature_range': (0, 1),\n",
       " 'clf__C': 1.0,\n",
       " 'clf__break_ties': False,\n",
       " 'clf__cache_size': 200,\n",
       " 'clf__class_weight': None,\n",
       " 'clf__coef0': 0.0,\n",
       " 'clf__decision_function_shape': 'ovr',\n",
       " 'clf__degree': 3,\n",
       " 'clf__gamma': 'scale',\n",
       " 'clf__kernel': 'rbf',\n",
       " 'clf__max_iter': -1,\n",
       " 'clf__probability': False,\n",
       " 'clf__random_state': None,\n",
       " 'clf__shrinking': True,\n",
       " 'clf__tol': 0.001,\n",
       " 'clf__verbose': False}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучение пайплайна работает с ColTransfromer, но не работает\n",
    "#  с OneHot непосредственно в пайплайне\n",
    "pipel.fit(X, y)\n",
    "pipel.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('clf', SVC())],\n",
       " 'verbose': False,\n",
       " 'clf': SVC(),\n",
       " 'clf__C': 1.0,\n",
       " 'clf__break_ties': False,\n",
       " 'clf__cache_size': 200,\n",
       " 'clf__class_weight': None,\n",
       " 'clf__coef0': 0.0,\n",
       " 'clf__decision_function_shape': 'ovr',\n",
       " 'clf__degree': 3,\n",
       " 'clf__gamma': 'scale',\n",
       " 'clf__kernel': 'rbf',\n",
       " 'clf__max_iter': -1,\n",
       " 'clf__probability': False,\n",
       " 'clf__random_state': None,\n",
       " 'clf__shrinking': True,\n",
       " 'clf__tol': 0.001,\n",
       " 'clf__verbose': False}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучили пайплан на Df, которая собрана вручную\n",
    "\n",
    "pipeline = Pipeline([('clf', SVC())])\n",
    "pipeline.fit(Df, y)\n",
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = pipeline.decision_function(Df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48842"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказанные значения на SVC\n",
    "abcc = pipeline.predict(Df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(abcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Посчитайте метрики accuracy и f1_score на предсказании только самого частого класса в целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       14\n",
       "14       \n",
       "0   37155\n",
       "1   11687"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y).groupby(y).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8667835671342685"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Самый частый класс - 0 (<= 50K)\n",
    "# Accuracy для самого частого класса - это Precision для этого класса TP/(TP+FP)\n",
    "# В качестве классификатора возьмем SVC\n",
    "\n",
    "# abcc = pipeline.predict(Df)\n",
    "\n",
    "precision_score(y, abcc, pos_label=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8978786895880637"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, abcc, pos_label=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Посчитайте cross_val_score по алгоритмам LogisticRegression, SVC, LinearSVC по метрикам accuracy и f1_score.\n",
    "Напишите удалось ли превзойти предыдущий результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8326441452759397"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вывод: в предыдущем шаге выбрали SVC. Для LinearSVC и LogRegr значение cross_val выше на 0,3%,\n",
    "#  precision и f1 выше на десятые % и ниже на десятые % соответственно\n",
    "\n",
    "\n",
    "# SVC\n",
    "\n",
    "cross_val_SVC = cross_val_score(pipeline, Df, y).mean()\n",
    "cross_val_SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8358586103109596"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_linearSVC = make_pipeline(LinearSVC())\n",
    "cross_val_linearSVC = cross_val_score(pipe_linearSVC, Df, y).mean()\n",
    "cross_val_linearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8358176665577627"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Для сходимости лог.регр-ии по гр.спуску задали max_iter\n",
    "pipe_regr = make_pipeline(LogisticRegression(max_iter=300))\n",
    "cross_val_regr = cross_val_score(pipe_regr, Df, y).mean()\n",
    "cross_val_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8677966955470482\n",
      "0.8965768485148129\n"
     ]
    }
   ],
   "source": [
    "pipe_linearSVC.fit(Df,y)\n",
    "abcc_linear = pipe_linearSVC.predict(Df)\n",
    "print(precision_score(y, abcc_linear, pos_label=0))\n",
    "print(f1_score(y, abcc_linear, pos_label=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8684662390788344\n",
      "0.8961527938819911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "pipe_regr.fit(Df,y)\n",
    "abcc_regr = pipe_regr.predict(Df)\n",
    "print(precision_score(y, abcc_regr, pos_label=0))\n",
    "print(f1_score(y, abcc_regr, pos_label=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Можно заметить что в данных присутствуют значения '?', замените их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values='?', strategy='most_frequent')\n",
    "imp.fit(X_obj)\n",
    "X_obj = imp.transform(X_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9   ...   89   90   91  \\\n",
       "48837  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "48838  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "48839  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "48840  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "48841  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "        92   93   94   95   96   97   98  \n",
       "48837  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "48838  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "48839  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "48840  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "48841  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(X_obj)\n",
    "\n",
    "a = enc.transform(X_obj).toarray()\n",
    "b = pd.DataFrame(a.tolist())\n",
    "b.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.137428</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643836</td>\n",
       "      <td>0.209130</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.245379</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369863</td>\n",
       "      <td>0.048444</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.053471</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246575</td>\n",
       "      <td>0.114919</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.415853</td>\n",
       "      <td>0.602041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9    ...  95   96   97   \\\n",
       "48837  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0   \n",
       "48838  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0   \n",
       "48839  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0   \n",
       "48840  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0   \n",
       "48841  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0   \n",
       "\n",
       "       98        99        100       101       102       103       104  \n",
       "48837  0.0  0.301370  0.137428  0.800000  0.149272  0.415853  0.357143  \n",
       "48838  0.0  0.643836  0.209130  0.533333  0.149272  0.415853  0.397959  \n",
       "48839  0.0  0.287671  0.245379  0.800000  0.149272  0.415853  0.500000  \n",
       "48840  0.0  0.369863  0.048444  0.800000  0.053471  0.415853  0.397959  \n",
       "48841  0.0  0.246575  0.114919  0.800000  0.149272  0.415853  0.602041  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df_1 = pd.concat([b, c], axis=1)\n",
    "Df_1.columns = [i for i in range(0,105)]\n",
    "Df_1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Посчитайте cross_val_score на новых данных. Напишите удалось ли улучшить результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Вопрос: Можно ли утверждать, что cross_val_score НЕ всегда (!) показывает наиболее оптимальную модель\n",
    "#  для обучения? Ведь при каждом шаге кросс-валидации класс-ор ищет другие оптимальные функции для класс-ции объектов\n",
    "# То есть SVC (как пример) с определенными параметрами показавший не луший cv_score (при выборе в grid search или по рез-ам cross_val_score.mean)\n",
    "#  может в целом по всем объектам строить наиболее оптимальную разделяющую плоскость для объектов (для тестовой выборки в неклассификационных моделях)\n",
    "\n",
    "# Изменение cross_val нулевое, однако в гугл коллаб разница получилась на 0,1-0,2%. \n",
    "# Как оптимизировать работу кода, ноут не мощный, но и в гугл коллаб выполняется более 10 минут\n",
    "\n",
    "cross_val_SVC_New = cross_val_score(pipe_SVC, Df_1, y).mean()\n",
    "\n",
    "cross_val_linearSVC_New = cross_val_score(pipe_linearSVC, Df_1, y).mean()\n",
    "\n",
    "cross_val_regr_New = cross_val_score(pipe_regr, Df_1, y).mean()\n",
    "\n",
    "print((cross_val_SVC_New-cross_val_SVC)*100, (cross_val_linearSVC_New-cross_val_linearSVC)*100,\n",
    " (cross_val_regr_New-cross_val_regr)*100, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Посчитайте cross_val_score, если просто удалить значения '?'. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48836</th>\n",
       "      <td>33</td>\n",
       "      <td>Private</td>\n",
       "      <td>245211</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>1902</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>1902</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>1902</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>1902</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>1902</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0             1       2          3   4                   5   \\\n",
       "48836  33       Private  245211  Bachelors  13       Never-married   \n",
       "48837  39       Private  215419  Bachelors  13            Divorced   \n",
       "48839  38       Private  374983  Bachelors  13  Married-civ-spouse   \n",
       "48840  44       Private   83891  Bachelors  13            Divorced   \n",
       "48841  35  Self-emp-inc  182148  Bachelors  13  Married-civ-spouse   \n",
       "\n",
       "                    6              7                   8       9      10  \\\n",
       "48836   Prof-specialty      Own-child               White    Male  15024   \n",
       "48837   Prof-specialty  Not-in-family               White  Female  15024   \n",
       "48839   Prof-specialty        Husband               White    Male  15024   \n",
       "48840     Adm-clerical      Own-child  Asian-Pac-Islander    Male   5455   \n",
       "48841  Exec-managerial        Husband               White    Male  15024   \n",
       "\n",
       "         11  12             13  14  \n",
       "48836  1902  40  United-States   0  \n",
       "48837  1902  36  United-States   0  \n",
       "48839  1902  50  United-States   0  \n",
       "48840  1902  40  United-States   0  \n",
       "48841  1902  60  United-States   1  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad = pd.concat([X, y], axis=1)\n",
    "\n",
    "ad = ad[ad!='?']\n",
    "ad.dropna(inplace=True)\n",
    "ad.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_X = ad.iloc[:,:-1]\n",
    "ad_y = ad.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19609]\n"
     ]
    }
   ],
   "source": [
    "# Столкнулся с проблемой при применении OneHot к датасету, так как\n",
    "#  одна из категорий 13 столбца осталась в количестве 1, убираем соотв. строку из дф\n",
    "# ValueError: Found unknown categories ['Holand-Netherlands'] in column 7 during transform\n",
    "print(ad_X[ad_X.iloc[:,13] == 'Holand-Netherlands'].index.values)\n",
    "ad_X_drop = ad_X.drop(19609)\n",
    "ad_y_drop = ad_y.drop(19609)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8291723284408465\n",
      "0.8327547187156263\n",
      "0.8322240045533794\n"
     ]
    }
   ],
   "source": [
    "# Результат хуже на десятые %\n",
    "trf = ColumnTransformer(transformers =[\n",
    "    ('cat', OneHotEncoder(sparse=False), [1, 3, 5, 6, 7, 8, 9, 13]),\n",
    "    ('num', MinMaxScaler(), [0, 2, 4, 10, 11, 12]),\n",
    "])\n",
    "\n",
    "pipel = Pipeline([\n",
    "    ('cat', trf), ('clf', SVC())\n",
    "])\n",
    "print(cross_val_score(pipel, ad_X_drop, ad_y_drop\n",
    "    ``).mean())\n",
    "\n",
    "pipel = Pipeline([\n",
    "    ('cat', trf), ('clf', LinearSVC())\n",
    "])\n",
    "print(cross_val_score(pipel, ad_X_drop, ad_y_drop\n",
    "    ``).mean())\n",
    "\n",
    "pipel = Pipeline([\n",
    "    ('cat', trf), ('clf', LogisticRegression(max_iter=300))\n",
    "])\n",
    "print(cross_val_score(pipel, ad_X_drop, ad_y_drop\n",
    "    ``).mean())\n",
    "\n",
    "#first_step = trf.fit_transform(X)\n",
    "#pd.DataFrame(first_step).head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 17. Посчитайте cross_val_score для RandomForestClassifier,GradientBoostingClassifier. Напишите как изменился результат и какой вывод можно из этого сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8368899812696311\n"
     ]
    }
   ],
   "source": [
    "# CV score вырос на несколько процентов на гр.бустинге и несущественно на рэндом форест\n",
    "# Вывод: наиболее подходящая среди моделей это гр.бустинг на масштабируемых очищенных данных \n",
    "\n",
    "# Вопрос: Почему традиционно считается что гр.бустинг применим только для класс-ии?\n",
    "#  Ведь можем улучшать некласс-ую модель, если требуется снизить смещение\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "pipel = Pipeline([\n",
    "    ('cat', trf), ('clf', RandomForestClassifier())\n",
    "])\n",
    "print(cross_val_score(pipel, ad_X_drop, ad_y_drop).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8603746978410811\n"
     ]
    }
   ],
   "source": [
    "pipel = Pipeline([\n",
    "    ('cat', trf), ('clf', GradientBoostingClassifier())\n",
    "])\n",
    "print(cross_val_score(pipel, ad_X_drop, ad_y_drop).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Подберите наилучшую модель, подбирая методы обработки колонок - масштабирование признаков, кодирование признаков и заполнение пропусков. Параметры алгоритмов оставьте по умолчанию. Выведите итоговые параметры и результат accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19609]\n"
     ]
    }
   ],
   "source": [
    "print(X[X.iloc[:,13] == 'Holand-Netherlands'].index.values)\n",
    "X_drop = X.drop(19609)\n",
    "y_drop = y.drop(19609)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8652975983292726"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MinMax, StScaler, OneHot, SimpleImputer\n",
    "# \n",
    "# Есть задача: применить OneHot к категор.колонкам и работать с остальной частью датафрейма в пайплайне,\n",
    "# перебирая MinMax, Scaler, Polynom (через grid_search)\n",
    "# Вопрос 1: - Можем ли мы засунуть машстабируемый метод в пайплайн так,\n",
    "#             чтобы он применился и заменил указанные колонки на преобразованные (а не оставил только эти колонки)?\n",
    "#          - Пробовал бороться с этим через ColTransformer, но колонки не заменяются а прибавляются последовательным применением\n",
    "#             разных функций (т.е. остаются в т.ч. начальные столбцы, если вторая функция применятся для тех же колонок что предыдущая)\n",
    "#          - Есть ли оптим. метод для решения такой задачи? Иначе нужно отдельно обрабатывать Df для использования в пайплайне, и не будет\n",
    "#             возможности перебрать в grid_search параметры SimpleImputer, OneHot для категор. фичей и другие методы для количеств-х фичей\n",
    "\n",
    "\n",
    "trf_a = ColumnTransformer(transformers = [\n",
    "    ('trf_a_1', OneHotEncoder(sparse=False), [1, 3, 5, 6, 7, 8, 9, 13]),\n",
    "    ('trf_a_2', MinMaxScaler(), [0, 2, 4, 10, 11, 12]),\n",
    "    ('trf_a_3', PolynomialFeatures(), [0, 2, 4, 10, 11, 12])\n",
    "    ])\n",
    "trf_b = ColumnTransformer(transformers = [\n",
    "    ('trf_b_1', OneHotEncoder(sparse=False), [1, 3, 5, 6, 7, 8, 9, 13]),\n",
    "    ('trf_b_2', StandardScaler(), [0, 2, 4, 10, 11, 12]),\n",
    "    ('trf_b_3', PolynomialFeatures(), [0, 2, 4, 10, 11, 12])\n",
    "    ])\n",
    "trf_c = ColumnTransformer(transformers = [\n",
    "    ('trf_c_1', OneHotEncoder(sparse=False), [1, 3, 5, 6, 7, 8, 9, 13]),\n",
    "    ('trf_c_2', MinMaxScaler(), [0, 2, 4, 10, 11, 12])\n",
    "    ])\n",
    "trf_d = ColumnTransformer(transformers = [\n",
    "    ('trf_d_1', OneHotEncoder(sparse=False), [1, 3, 5, 6, 7, 8, 9, 13]),\n",
    "    ('trf_d_2', StandardScaler(), [0, 2, 4, 10, 11, 12])\n",
    "    ])\n",
    "# trf_complex = ColumnTransformer(transformers = [\n",
    "#    ('trf_a_1', MinMaxScaler(), [0, 2, 4, 10, 11, 12]),\n",
    "#    ('trf_a_2', OneHotEncoder(sparse=False), [1, 3, 5, 6, 7, 8, 9, 13])\n",
    "#    ('trf_a_3', PolynomialFeatures())\n",
    "#    ], sparse_threshold=0)\n",
    "# На всех фичах полином будет долго работать...\n",
    "\n",
    "pipeline = Pipeline([('transform_2', trf_a), ('clf', SVC())])\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        'transform_2': (trf_a, trf_b, trf_c, trf_d),\n",
    "\n",
    "        'clf': (SVC(),LinearSVC(), LogisticRegression(max_iter=300)),\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5)\n",
    "grid_search.fit(X_drop, y_drop)\n",
    "best_clf = grid_search.best_estimator_\n",
    "score = best_clf.score(X_drop, y_drop)\n",
    "score\n",
    "\n",
    "# C учетом того что при применении функция в ColTransf для одних и тех же фичей у нас не происходит замещений значений,\n",
    "#  как вариант можно убрать полином из trf_a и trf_b, и добавить его в пайплайн с подбором по degree: [1,2], но тогда полином применится\n",
    "#  в т.ч. к отсортированным по OneHot. SimpleImputer можно обернуть еще в один ColTrans по нужным фичам, \n",
    "#  а по оставшимся колонкам применить нейтральную вставку (подойдет SimpleImputer без параметров).\n",
    "# Но для применения grid_search слишком много ColTransf... Данный код выполнялся 74 минуты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('transform_2',\n",
       "   ColumnTransformer(transformers=[('trf_d_1', OneHotEncoder(sparse=False),\n",
       "                                    [1, 3, 5, 6, 7, 8, 9, 13]),\n",
       "                                   ('trf_d_2', StandardScaler(),\n",
       "                                    [0, 2, 4, 10, 11, 12])])),\n",
       "  ('clf', SVC())],\n",
       " 'verbose': False,\n",
       " 'transform_2': ColumnTransformer(transformers=[('trf_d_1', OneHotEncoder(sparse=False),\n",
       "                                  [1, 3, 5, 6, 7, 8, 9, 13]),\n",
       "                                 ('trf_d_2', StandardScaler(),\n",
       "                                  [0, 2, 4, 10, 11, 12])]),\n",
       " 'clf': SVC(),\n",
       " 'transform_2__n_jobs': None,\n",
       " 'transform_2__remainder': 'drop',\n",
       " 'transform_2__sparse_threshold': 0.3,\n",
       " 'transform_2__transformer_weights': None,\n",
       " 'transform_2__transformers': [('trf_d_1',\n",
       "   OneHotEncoder(sparse=False),\n",
       "   [1, 3, 5, 6, 7, 8, 9, 13]),\n",
       "  ('trf_d_2', StandardScaler(), [0, 2, 4, 10, 11, 12])],\n",
       " 'transform_2__verbose': False,\n",
       " 'transform_2__verbose_feature_names_out': True,\n",
       " 'transform_2__trf_d_1': OneHotEncoder(sparse=False),\n",
       " 'transform_2__trf_d_2': StandardScaler(),\n",
       " 'transform_2__trf_d_1__categories': 'auto',\n",
       " 'transform_2__trf_d_1__drop': None,\n",
       " 'transform_2__trf_d_1__dtype': numpy.float64,\n",
       " 'transform_2__trf_d_1__handle_unknown': 'error',\n",
       " 'transform_2__trf_d_1__max_categories': None,\n",
       " 'transform_2__trf_d_1__min_frequency': None,\n",
       " 'transform_2__trf_d_1__sparse': False,\n",
       " 'transform_2__trf_d_2__copy': True,\n",
       " 'transform_2__trf_d_2__with_mean': True,\n",
       " 'transform_2__trf_d_2__with_std': True,\n",
       " 'clf__C': 1.0,\n",
       " 'clf__break_ties': False,\n",
       " 'clf__cache_size': 200,\n",
       " 'clf__class_weight': None,\n",
       " 'clf__coef0': 0.0,\n",
       " 'clf__decision_function_shape': 'ovr',\n",
       " 'clf__degree': 3,\n",
       " 'clf__gamma': 'scale',\n",
       " 'clf__kernel': 'rbf',\n",
       " 'clf__max_iter': -1,\n",
       " 'clf__probability': False,\n",
       " 'clf__random_state': None,\n",
       " 'clf__shrinking': True,\n",
       " 'clf__tol': 0.001,\n",
       " 'clf__verbose': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Лучший вариант это стандартизация с моделью опорных векторов\n",
    "best_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;transform_2&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;trf_d_1&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [1, 3, 5, 6, 7, 8, 9, 13]),\n",
       "                                                 (&#x27;trf_d_2&#x27;, StandardScaler(),\n",
       "                                                  [0, 2, 4, 10, 11, 12])])),\n",
       "                (&#x27;clf&#x27;, SVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;transform_2&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;trf_d_1&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [1, 3, 5, 6, 7, 8, 9, 13]),\n",
       "                                                 (&#x27;trf_d_2&#x27;, StandardScaler(),\n",
       "                                                  [0, 2, 4, 10, 11, 12])])),\n",
       "                (&#x27;clf&#x27;, SVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transform_2: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;trf_d_1&#x27;, OneHotEncoder(sparse=False),\n",
       "                                 [1, 3, 5, 6, 7, 8, 9, 13]),\n",
       "                                (&#x27;trf_d_2&#x27;, StandardScaler(),\n",
       "                                 [0, 2, 4, 10, 11, 12])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">trf_d_1</label><div class=\"sk-toggleable__content\"><pre>[1, 3, 5, 6, 7, 8, 9, 13]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">trf_d_2</label><div class=\"sk-toggleable__content\"><pre>[0, 2, 4, 10, 11, 12]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('transform_2',\n",
       "                 ColumnTransformer(transformers=[('trf_d_1',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [1, 3, 5, 6, 7, 8, 9, 13]),\n",
       "                                                 ('trf_d_2', StandardScaler(),\n",
       "                                                  [0, 2, 4, 10, 11, 12])])),\n",
       "                ('clf', SVC())])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.fit(X_drop, y_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8843301405334741\n",
      "0.9144818083737375\n"
     ]
    }
   ],
   "source": [
    "predict = best_clf.predict(X_drop)\n",
    "print(precision_score(y_drop, predict, pos_label=0))\n",
    "print(f1_score(y_drop, predict, pos_label=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\brigh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8696177391945292"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Для решения проблемы в ColTransf можно встроить пайплайн, но есть ли более оптимальное?\n",
    "#  Это решение не позволит нам перебирать параметры трансформаторов в grid_search\n",
    "#  Код выполнялся более часа\n",
    "# Вопрос 2: Есть предположение, что после OneHot нет смысла использовать доп. масштабирование, верно ли?\n",
    "#  Классификатор четко разбивает по колонкам, и видимо нет смысла переобучать. А полином применять на нормализованные значения\n",
    "\n",
    "trf_a = ColumnTransformer([\n",
    "    ('trf_a_1', OneHotEncoder(sparse=False), [1, 3, 5, 6, 7, 8, 9, 13]),\n",
    "    ('trf_a_2', Pipeline([\n",
    "        ('1', MinMaxScaler()),\n",
    "        ('2', PolynomialFeatures())\n",
    "        ]), [0, 2, 4, 10, 11, 12]) \n",
    "    ], remainder ='passthrough')\n",
    "\n",
    "\n",
    "pipeline = Pipeline([('transform', trf_a), ('clf', SVC())])\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        'transform__transformers': ([\n",
    "    ('trf_a_1', OneHotEncoder(sparse=False), [1, 3, 5, 6, 7, 8, 9, 13]),\n",
    "    ('trf_a_2', Pipeline([\n",
    "        ('1', MinMaxScaler()),\n",
    "        ('2', PolynomialFeatures())\n",
    "        ]), [0, 2, 4, 10, 11, 12]) \n",
    "    ],\n",
    "\n",
    "    [ # Убираем '?' и применяем MinMax вместо Standart\n",
    "    ('trf_a_1', Pipeline([\n",
    "        ('1', SimpleImputer(missing_values='?', strategy='most_frequent')),\n",
    "        ('2', OneHotEncoder(sparse=False))\n",
    "        ]), [1, 3, 5, 6, 7, 8, 9, 13]),\n",
    "    ('trf_a_2', Pipeline([\n",
    "        ('1', StandardScaler()),\n",
    "        ('2', PolynomialFeatures())\n",
    "        ]), [0, 2, 4, 10, 11, 12]) \n",
    "    ]),\n",
    "\n",
    "        'clf': (SVC(),LinearSVC(), LogisticRegression(max_iter=300),\n",
    "        GradientBoostingClassifier(), RandomForestClassifier()),\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_search_1 = GridSearchCV(pipeline, parameters, cv=5)\n",
    "grid_search_1.fit(X_drop, y_drop)\n",
    "best_clf_1 = grid_search_1.best_estimator_\n",
    "score_1 = best_clf_1.score(X_drop, y_drop)\n",
    "score_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.885036770223623\n",
      "0.9174402323289944\n"
     ]
    }
   ],
   "source": [
    "# Еще более высокие значения\n",
    "\n",
    "best_clf_1.fit(X_drop, y_drop)\n",
    "predict = best_clf_1.predict(X_drop)\n",
    "print(precision_score(y_drop, predict, pos_label=0))\n",
    "print(f1_score(y_drop, predict, pos_label=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если бы работало быстро, то можно было б запустить полноценный отбор ниже\n",
    "\n",
    "### Заметка: В ColTrans не работает make_pipline, который позволяет не называть трансформаторы\n",
    "\n",
    "trf_a = ColumnTransformer([\n",
    "    ('1', MinMaxScaler(), [0, 2, 4, 10, 11, 12])\n",
    "    ], remainder ='passthrough')\n",
    "\n",
    "trf_b = ColumnTransformer([\n",
    "    ('1', OneHotEncoder(sparse=False), [1, 3, 5, 6, 7, 8, 9, 13])\n",
    "    ], remainder ='passthrough')\n",
    "\n",
    "pipeline = Pipeline([('transform1', trf_a), ('transform2', trf_b), ('clf', SVC())])\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        'transform1__transformers': ([\n",
    "    ('1', MinMaxScaler(), [0, 2, 4, 10, 11, 12]) \n",
    "    ],\n",
    "\n",
    "    [\n",
    "    ('1', StandardScaler(), [0, 2, 4, 10, 11, 12]) \n",
    "    ],\n",
    "\n",
    "    [\n",
    "    ('1', Pipeline([\n",
    "        ('1', StandardScaler()),\n",
    "        ('2', PolynomialFeatures())\n",
    "        ]), [0, 2, 4, 10, 11, 12])\n",
    "    ],\n",
    "\n",
    "    [\n",
    "    ('1', Pipeline([\n",
    "        ('1', MinMaxScaler()),\n",
    "        ('2', PolynomialFeatures())\n",
    "        ]), [0, 2, 4, 10, 11, 12])\n",
    "    ]),\n",
    "  \n",
    "        'transform2__transformers': ([       \n",
    "    ('1', OneHotEncoder(sparse=False), [1, 3, 5, 6, 7, 8, 9, 13]) \n",
    "    ],\n",
    "\n",
    "    [\n",
    "    ('1', Pipeline([\n",
    "        ('1', SimpleImputer(missing_values='?', strategy='most_frequent')),\n",
    "        ('2', OneHotEncoder(sparse=False))\n",
    "        ]), [1, 3, 5, 6, 7, 8, 9, 13])\n",
    "    ]),\n",
    "\n",
    "        'clf': (SVC(),LinearSVC(), LogisticRegression(max_iter=300),\n",
    "        GradientBoostingClassifier(), RandomForestClassifier()),\n",
    "    }\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8750a921b84a1b624817dbfae33fa28d408c1c697f0b181b4279f7947f553d12"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
