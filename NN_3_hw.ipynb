{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST('/Users/a14419009/Repos/NN_reload_stream2', download=True)\n",
    "\n",
    "def collate_fn(data):\n",
    "    pics = []\n",
    "    target = []\n",
    "    for item in data:\n",
    "\n",
    "        pics.append(numpy.array(item[0]))\n",
    "        target.append(item[1])\n",
    "    return {\n",
    "        'data': torch.from_numpy(numpy.array(pics)).float() / 255,\n",
    "        'target': torch.from_numpy(numpy.array(target)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper params\n",
    "num_epoch = 1\n",
    "cuda_device = -1\n",
    "batch_size = 222\n",
    "device = f'cuda:{cuda_device}' if cuda_device != -1 else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    # 28*28 -> hidden -> out\n",
    "    def __init__(self, in_chan, hidden_ch, out_channels):\n",
    "        super().__init__()\n",
    "        #conv2d -> maxpool2d -> conv2d -> maxpool2d -> conv2d\n",
    "        self.conv1 = nn.Conv2d(in_chan, hidden_ch, kernel_size=5, stride=1, padding=2) # 28 x 28\n",
    "        self.pool1 = nn.MaxPool2d(4, 4) # 14 x 14\n",
    "        #self.conv2 = nn.Conv2d(hidden_ch, hidden_ch, kernel_size=3, stride=1, padding=1)  # 14 x 14\n",
    "        #self.pool2 = nn.MaxPool2d(2, 2)  # 7 x 7\n",
    "        self.conv3 = nn.Conv2d(hidden_ch, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x): # -> 7x7\n",
    "        x = self.activation(self.pool1(self.conv1(x)))\n",
    "        #x = self.activation(self.pool2(self.conv2(x)))\n",
    "        x = self.activation(self.conv3(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    #conv2d -> upsampling2d -> conv2d -> upsampling2d -> conv2d\n",
    "    def __init__(self, in_chan, hidden_ch, out_chan):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_chan, hidden_ch, kernel_size=3, stride=1, padding=1)  # 7 x 7\n",
    "        self.upsample1 = nn.UpsamplingNearest2d(scale_factor=4)  # 14 x 14\n",
    "        #self.conv2 = nn.Conv2d(hidden_ch, hidden_ch, kernel_size=3, stride=1, padding=1)  # 14 x 14\n",
    "        #self.upsample2 = nn.UpsamplingNearest2d(scale_factor=2)  # 28 x 28\n",
    "        self.conv3 = nn.Conv2d(hidden_ch, out_chan, kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x): # -> 28 x 28\n",
    "        x = self.activation(self.upsample1(self.conv1(x)))\n",
    "        #x = self.activation(self.upsample2(self.conv2(x)))\n",
    "        x = self.activation(self.conv3(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_ch, enc_hidden_ch, dec_hidden_ch, latent_ch):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_ch, enc_hidden_ch, latent_ch)\n",
    "        self.decoder = Decoder(latent_ch, dec_hidden_ch, input_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(1, 50, 40, 1)\n",
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1054, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch: 0\n",
      "tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1\n",
      "tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2\n",
      "tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3\n",
      "tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4\n",
      "tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5\n",
      "tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6\n",
      "tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7\n",
      "tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8\n",
      "tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        collate_fn=collate_fn,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        data = batch['data'].to(device).unsqueeze(1)\n",
    "        optim.zero_grad()\n",
    "        predict = model(data)\n",
    "        loss = loss_func(predict, data)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if (step % 100 == 0):\n",
    "            print(loss)\n",
    "    print(f'epoch: {epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.5110, 0.6649, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.2805, 0.9829, 1.1666, 0.6336, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.4032, 1.0146, 1.1848, 0.7662, 0.0081,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.2477, 0.9389, 1.2291, 0.8884, 0.2020,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0752, 0.8479, 1.2299, 0.9769, 0.3122,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.7873, 1.2186, 1.0198, 0.3844,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.6042, 1.0550, 0.9481, 0.3531,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.6633, 1.1154, 0.9965, 0.3730,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.7871, 1.2248, 1.0168, 0.3954,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.8105, 1.2136, 1.0261, 0.4764,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.6900, 1.0913, 1.0661, 0.6643,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.5810, 1.0278, 1.0624, 0.8061,\n",
       "           0.2004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.3518, 0.8653, 1.0009, 0.9347,\n",
       "           0.4799, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1242, 0.6870, 0.9450, 1.0404,\n",
       "           0.7432, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1644, 0.7813, 1.0179, 1.1198,\n",
       "           0.8321, 0.0488, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6283, 0.9422, 1.1278,\n",
       "           0.9273, 0.1947, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5065, 0.9274, 1.2155,\n",
       "           1.1074, 0.4098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4220, 0.9235, 1.2307,\n",
       "           1.1935, 0.5267, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3065, 0.8880, 1.1720,\n",
       "           1.0182, 0.2936, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5235, 0.7101,\n",
       "           0.4718, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test = dataset.data[200].unsqueeze(0).unsqueeze(0).float() / 255\n",
    "    predict = model(test)\n",
    "\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = predict.view(torch.squeeze(predict).size())\n",
    "\n",
    "plt.imshow(sample.detach().numpy()/255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAMB0lEQVR4nO3dbYhc5RnG8esyjRGjQqJ2WaP4mhak0Nhuo0VpLVLxDaJfxHyQFCwrRUHBDxULar9JqYqgiKsG09YXpCoGqq1psIiiqatNNdHWqERMWLOVlBqFxhjvftgTWePOmc2cc+ZM9/7/YJiZ88yZczPkynPmPPPs44gQgLnvoLYLANAfhB1IgrADSRB2IAnCDiTxtX4e7GAviEO0sJ+HBFL5rz7Rp7HbM7VVCrvt8yTdIWmepPsi4pay1x+ihTrd51Q5JIASG2J9x7aeT+Ntz5N0l6TzJZ0qaaXtU3t9PwDNqvKdfbmktyPi3Yj4VNIjklbUUxaAulUJ+xJJ7097vq3Y9iW2R22P2x7fo90VDgegisavxkfEWESMRMTIfC1o+nAAOqgS9u2Sjpv2/NhiG4ABVCXsL0taavtE2wdLukzS2nrKAlC3nofeIuIz21dL+pOmht5WR8Tm2ioDUKtK4+wR8ZSkp2qqBUCD+LkskARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0n0dclmNGPeN0/p2HbS797v2CZJdy7ZUNo+ctPPStuPvPfF0nYMDnp2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfY5YMcPj+7Y9vvhh0r33RPzyt88eqkIg6hS2G1vlbRL0l5Jn0XESB1FAahfHT37jyLiwxreB0CD+M4OJFE17CHpGduv2B6d6QW2R22P2x7fo90VDwegV1VP48+KiO22vy5pne1/RMRz018QEWOSxiTpCC/mcg/Qkko9e0RsL+4nJT0haXkdRQGoX89ht73Q9uH7Hks6V9KmugoDUK8qp/FDkp6wve99HoqIP9ZSFQ6MOzfNd/k4+kFlO0t68Zd3lrZfdN93S9sxOHoOe0S8K+nbNdYCoEEMvQFJEHYgCcIOJEHYgSQIO5AEU1zngpLfJe6JvaW7dhua67Y//n/QswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzzwUNTnHttv+//7C0tH3RhVtK29E/9OxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7HNBi/PZI8rH6TE46NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2eeCFuez2yWD/BgoXXt226ttT9reNG3bYtvrbG8p7hc1WyaAqmZzGv+ApPP223a9pPURsVTS+uI5gAHWNewR8ZyknfttXiFpTfF4jaSL6y0LQN16/c4+FBETxeMPJA11eqHtUUmjknSIDu3xcACqqnw1PiJCJVMxImIsIkYiYmS+FlQ9HIAe9Rr2HbaHJam4n6yvJABN6DXsayWtKh6vkvRkPeUAaErX7+y2H5Z0tqSjbG+TdJOkWyQ9avsKSe9JurTJIlFu6NnOJ1bX/PTM0n3vOOaF0nbms88dXcMeESs7NJ1Tcy0AGsTPZYEkCDuQBGEHkiDsQBKEHUiCKa5zwN633unYNj5ZvqTyQccwxTULenYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9jmu2xTUz8vWexZTXOcSenYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9jmu23xzlmzOg54dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnH2OYz479unas9tebXvS9qZp2262vd32xuJ2QbNlAqhqNqfxD0g6b4btt0fEsuL2VL1lAahb17BHxHOSdvahFgANqnKB7mrbrxWn+Ys6vcj2qO1x2+N7tLvC4QBU0WvY75Z0sqRlkiYk3drphRExFhEjETEyXwt6PByAqnoKe0TsiIi9EfG5pHslLa+3LAB16ynstoenPb1E0qZOrwUwGLqOs9t+WNLZko6yvU3STZLOtr1MUkjaKunK5kpEFYsvequ0/aDt1eazv3TaI6Xtp9zT+Z/GN658uXRf1Ktr2CNi5Qyb72+gFgAN4ueyQBKEHUiCsANJEHYgCcIOJMEU1+SqTnHtNjS3+cK7OrZdwm+x+oqeHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJw9uapLNlfZf/f53yvdd8HTTIGtEz07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOHtyTc9nL9v/k6v+U7rvgqdLm3GA6NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2ZO7buKM0vZbh18qba8yn33Xq0eW7ru4tBUHqmvPbvs428/afsP2ZtvXFNsX215ne0txv6j5cgH0ajan8Z9Jui4iTpV0hqSrbJ8q6XpJ6yNiqaT1xXMAA6pr2CNiIiJeLR7vkvSmpCWSVkhaU7xsjaSLG6oRQA0O6Du77RMknSZpg6ShiJgomj6QNNRhn1FJo5J0iA7tuVAA1cz6arztwyQ9JunaiPhoeltEhDTzjIqIGIuIkYgYma8FlYoF0LtZhd32fE0F/cGIeLzYvMP2cNE+LGmymRIB1KHrabxtS7pf0psRcdu0prWSVkm6pbh/spEK0agXxkZK2/fc+EJpe5Uprsff+GLpvqjXbL6znynpckmv295YbLtBUyF/1PYVkt6TdGkjFQKoRdewR8TzUsdfTpxTbzkAmsLPZYEkCDuQBGEHkiDsQBKEHUiCKa4o1eSSzegvenYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9uSG/lL+N0e+//nVpe3Lr/xbaftf7zmtY9uRYj57P9GzA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASnlrMpT+O8OI43fxBWqApG2K9PoqdM/6RAXp2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiia9htH2f7Wdtv2N5s+5pi+822t9veWNwuaL5cAL2azR+v+EzSdRHxqu3DJb1ie13RdntE/Lq58gDUZTbrs09Imige77L9pqQlTRcGoF4H9J3d9gmSTpO0odh0te3XbK+2vajDPqO2x22P79HuatUC6Nmsw277MEmPSbo2Ij6SdLekkyUt01TPf+tM+0XEWESMRMTIfC2oXjGAnswq7LbnayroD0bE45IUETsiYm9EfC7pXknLmysTQFWzuRpvSfdLejMibpu2fXjayy6RtKn+8gDUZTZX48+UdLmk121vLLbdIGml7WWSQtJWSVc2UB+Amszmavzz0oyLcD9VfzkAmsIv6IAkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0n0dclm2/+S9N60TUdJ+rBvBRyYQa1tUOuSqK1XddZ2fEQcPVNDX8P+lYPb4xEx0loBJQa1tkGtS6K2XvWrNk7jgSQIO5BE22Efa/n4ZQa1tkGtS6K2XvWltla/swPon7Z7dgB9QtiBJFoJu+3zbP/T9tu2r2+jhk5sb7X9erEM9XjLtay2PWl707Rti22vs72luJ9xjb2WahuIZbxLlhlv9bNre/nzvn9ntz1P0luSfixpm6SXJa2MiDf6WkgHtrdKGomI1n+AYfsHkj6W9JuI+Fax7VeSdkbELcV/lIsi4ucDUtvNkj5uexnvYrWi4enLjEu6WNJP1OJnV1LXperD59ZGz75c0tsR8W5EfCrpEUkrWqhj4EXEc5J27rd5haQ1xeM1mvrH0ncdahsIETEREa8Wj3dJ2rfMeKufXUldfdFG2JdIen/a820arPXeQ9Iztl+xPdp2MTMYioiJ4vEHkobaLGYGXZfx7qf9lhkfmM+ul+XPq+IC3VedFRHfkXS+pKuK09WBFFPfwQZp7HRWy3j3ywzLjH+hzc+u1+XPq2oj7NslHTft+bHFtoEQEduL+0lJT2jwlqLesW8F3eJ+suV6vjBIy3jPtMy4BuCza3P58zbC/rKkpbZPtH2wpMskrW2hjq+wvbC4cCLbCyWdq8FbinqtpFXF41WSnmyxli8ZlGW8Oy0zrpY/u9aXP4+Ivt8kXaCpK/LvSPpFGzV0qOskSX8vbpvbrk3Sw5o6rdujqWsbV0g6UtJ6SVsk/VnS4gGq7beSXpf0mqaCNdxSbWdp6hT9NUkbi9sFbX92JXX15XPj57JAElygA5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk/gfvkrxcJWQDyQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset.data[200].detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AE denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = AutoEncoder(1, 50, 40, 1)\n",
    "model_1.train()\n",
    "model_1.to(device)\n",
    "\n",
    "optim_1 = torch.optim.Adam(model_1.parameters(), lr=0.001)\n",
    "loss_func_1 = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1124, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1132, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1146, grad_fn=<MseLossBackward0>)\n",
      "epoch: 0\n",
      "tensor(0.1108, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1109, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1090, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1\n",
      "tensor(0.1068, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1076, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1162, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2\n",
      "tensor(0.1073, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1123, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1067, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3\n",
      "tensor(0.1137, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1107, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1100, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4\n",
      "tensor(0.1090, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1138, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1076, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5\n",
      "tensor(0.1172, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1145, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1134, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6\n",
      "tensor(0.1109, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1150, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1085, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7\n",
      "tensor(0.1118, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1127, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1098, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8\n",
      "tensor(0.1088, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1133, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1106, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        collate_fn=collate_fn,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        data = batch['data'].to(device).unsqueeze(1)\n",
    "        data_noized = torch.clamp(data + 0.5 * torch.normal(torch.zeros_like(data), torch.ones_like(data)), 0., 1.)\n",
    "        optim_1.zero_grad()\n",
    "        predict = model_1(data_noized)\n",
    "        loss = loss_func_1(predict, data)\n",
    "        loss.backward()\n",
    "        optim_1.step()\n",
    "        if (step % 100 == 0):\n",
    "            print(loss)\n",
    "    print(f'epoch: {epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.train()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_1.eval()\n",
    "    test = dataset.data[784].unsqueeze(0).unsqueeze(0).float() / 255\n",
    "    test = torch.clamp(test + 0.5 * torch.normal(torch.zeros_like(test), torch.ones_like(test)), 0., 1.0)\n",
    "    predict = model_1(test)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Модель не распознала шум? Слишком долго выполняется код, нет возможности\n",
    "#    покрутить модель. На изначальных параметрах модели тоже пустая картинка..\n",
    "sample = predict.view(torch.squeeze(predict).size())\n",
    "\n",
    "plt.imshow(sample.detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    # 28*28 -> hidden -> out\n",
    "    def __init__(self, in_chan, hidden_ch, out_channels):\n",
    "        super().__init__()\n",
    "        #conv2d -> maxpool2d -> conv2d -> maxpool2d -> conv2d\n",
    "        self.conv1 = nn.Conv2d(in_chan, hidden_ch, kernel_size=7, stride=1, padding=3) # 28 x28\n",
    "        self.pool1 = nn.MaxPool2d(2, 2) # 14 x 14\n",
    "        self.conv2 = nn.Conv2d(hidden_ch, hidden_ch, kernel_size=3, stride=1, padding=1)  # 14 x 14\n",
    "        self.pool2 = nn.AvgPool2d(2, 2)  # 7 x 7\n",
    "        self.conv_mu = nn.Conv2d(hidden_ch, out_channels, kernel_size=4, stride=1, padding=2)\n",
    "        self.conv_sigma = nn.Conv2d(hidden_ch, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x): # -> 7x7\n",
    "        x = self.activation(self.pool1(self.conv1(x)))\n",
    "        x = self.activation(self.pool2(self.conv2(x)))\n",
    "        mu = self.activation(self.conv_mu(x))\n",
    "        sigma = torch.exp(self.conv_sigma(x))\n",
    "\n",
    "        return mu, sigma\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    #conv2d -> upsampling2d -> conv2d -> upsampling2d -> conv2d\n",
    "    def __init__(self, in_chan, hidden_ch, out_chan):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_chan, hidden_ch, kernel_size=3, stride=1, padding=1)  # 7 x 7\n",
    "        self.upsample1 = nn.UpsamplingNearest2d(scale_factor=2)  # 14 x 14\n",
    "        self.conv2 = nn.Conv2d(hidden_ch, hidden_ch, kernel_size=3, stride=1, padding=1)  # 14 x 14\n",
    "        self.upsample2 = nn.UpsamplingNearest2d(scale_factor=2)  # 28 x 28\n",
    "        self.conv3 = nn.Conv2d(hidden_ch, out_chan, kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x): # -> 28 x 28\n",
    "        x = self.activation(self.upsample1(self.conv1(x)))\n",
    "        x = self.activation(self.upsample2(self.conv2(x)))\n",
    "        x = self.activation(self.conv3(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_ch, enc_hidden_ch, dec_hidden_ch, latent_ch):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_ch, enc_hidden_ch, latent_ch)\n",
    "        self.decoder = Decoder(latent_ch, dec_hidden_ch, input_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, sigma = self.encoder(x)\n",
    "        x = sampling(mu, sigma)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling\n",
    "def sampling(mu, sigma):\n",
    "    return mu + sigma * torch.normal(torch.zeros_like(sigma),\n",
    "                                     torch.ones_like(sigma))\n",
    "\n",
    "\n",
    "def collate_fn(data):\n",
    "    pics = []\n",
    "    target = []\n",
    "    for item in data:\n",
    "\n",
    "        pics.append(numpy.array(item[0]))\n",
    "        target.append(item[1])\n",
    "    return {\n",
    "        'data': torch.from_numpy(numpy.array(pics)).float() / 255,\n",
    "        'target': torch.from_numpy(numpy.array(target)),\n",
    "    }\n",
    "\n",
    "\n",
    "def kl_loss(mu, sigma):\n",
    "    p = torch.distributions.Normal(mu, sigma)\n",
    "    q = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(sigma))\n",
    "\n",
    "    return torch.distributions.kl_divergence(p, q).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = AutoEncoder(1, 50, 45, 1)\n",
    "model2.train()\n",
    "model2.to(device)\n",
    "\n",
    "optim2 = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
    "criterion2 = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kl_loss: 0.0014852631138637662, criterion_loss: 0.1130523830652237\n",
      "kl_loss: 0.03134269267320633, criterion_loss: 0.07359606772661209\n",
      "kl_loss: 0.02940024621784687, criterion_loss: 0.0704735666513443\n",
      "epoch: 0\n",
      "kl_loss: 0.027482330799102783, criterion_loss: 0.06930218636989594\n",
      "kl_loss: 0.0398651659488678, criterion_loss: 0.0647791400551796\n",
      "kl_loss: 0.04211898148059845, criterion_loss: 0.06369849294424057\n",
      "epoch: 1\n",
      "kl_loss: 0.048332203179597855, criterion_loss: 0.06467343866825104\n",
      "kl_loss: 0.04849981144070625, criterion_loss: 0.06353256851434708\n",
      "kl_loss: 0.04838209226727486, criterion_loss: 0.06373150646686554\n",
      "epoch: 2\n",
      "kl_loss: 0.04761927202343941, criterion_loss: 0.06309276819229126\n",
      "kl_loss: 0.04830648750066757, criterion_loss: 0.06315804272890091\n",
      "kl_loss: 0.05074344947934151, criterion_loss: 0.06296658515930176\n",
      "epoch: 3\n",
      "kl_loss: 0.05386507883667946, criterion_loss: 0.06321109086275101\n",
      "kl_loss: 0.04931560531258583, criterion_loss: 0.06420785933732986\n",
      "kl_loss: 0.05263017490506172, criterion_loss: 0.060719117522239685\n",
      "epoch: 4\n",
      "kl_loss: 0.0585627555847168, criterion_loss: 0.06217387318611145\n",
      "kl_loss: 0.05548868328332901, criterion_loss: 0.059855591505765915\n",
      "kl_loss: 0.05935681238770485, criterion_loss: 0.06331410259008408\n",
      "epoch: 5\n",
      "kl_loss: 0.058216243982315063, criterion_loss: 0.061132751405239105\n",
      "kl_loss: 0.05605241283774376, criterion_loss: 0.06270753592252731\n",
      "kl_loss: 0.05865823104977608, criterion_loss: 0.06211857125163078\n",
      "epoch: 6\n",
      "kl_loss: 0.05810575559735298, criterion_loss: 0.05997481197118759\n",
      "kl_loss: 0.05526620149612427, criterion_loss: 0.06026178598403931\n",
      "kl_loss: 0.05681540444493294, criterion_loss: 0.061399269849061966\n",
      "epoch: 7\n",
      "kl_loss: 0.06251692026853561, criterion_loss: 0.05982087180018425\n",
      "kl_loss: 0.06188216432929039, criterion_loss: 0.061001501977443695\n",
      "kl_loss: 0.05854532867670059, criterion_loss: 0.06130848452448845\n",
      "epoch: 8\n",
      "kl_loss: 0.06186364218592644, criterion_loss: 0.061423372477293015\n",
      "kl_loss: 0.06382956355810165, criterion_loss: 0.0624057836830616\n",
      "kl_loss: 0.05904495343565941, criterion_loss: 0.061180539429187775\n",
      "epoch: 9\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        collate_fn=collate_fn,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        data = batch['data'].to(device).unsqueeze(1)\n",
    "        optim2.zero_grad()\n",
    "        \n",
    "        predict, mu, sigma = model2(data)\n",
    "        #loss\n",
    "        kl = kl_loss(mu, sigma)\n",
    "        crit_loss = criterion2(data, predict)\n",
    "        loss = 0.1 * kl + crit_loss\n",
    "        loss.backward()\n",
    "        optim2.step()\n",
    "        if (step % 100 == 0):\n",
    "            print('kl_loss: {}, criterion_loss: {}'.format(kl.item(), crit_loss.item()))\n",
    "    print(f'epoch: {epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3246e-03,\n",
       "            7.4230e-02, 8.8164e-02, 1.7716e-02, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7317e-02,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2045e-01, 2.8925e-01,\n",
       "            3.6495e-01, 3.5474e-01, 2.2423e-01, 1.8561e-01, 1.7039e-01,\n",
       "            1.2896e-01, 1.5225e-01, 1.9781e-01, 3.0975e-01, 3.9030e-01,\n",
       "            2.9195e-01, 1.8556e-01, 6.5669e-02, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 1.1658e-01, 3.3553e-01, 4.1620e-01,\n",
       "            4.9682e-01, 4.5998e-01, 3.1910e-01, 2.6268e-01, 2.0796e-01,\n",
       "            1.8289e-01, 2.3282e-01, 3.2984e-01, 4.4599e-01, 5.0967e-01,\n",
       "            4.3650e-01, 2.9330e-01, 1.2089e-01, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1159e-02,\n",
       "            4.7756e-02, 1.2304e-01, 2.6025e-01, 4.6273e-01, 5.4888e-01,\n",
       "            5.9224e-01, 5.4400e-01, 3.9637e-01, 3.1390e-01, 2.8262e-01,\n",
       "            2.9075e-01, 3.4742e-01, 4.6592e-01, 6.2727e-01, 6.5766e-01,\n",
       "            5.2267e-01, 3.8222e-01, 1.9192e-01, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0587e-01,\n",
       "            1.1377e-01, 1.9818e-01, 3.4041e-01, 5.4041e-01, 5.8806e-01,\n",
       "            6.2580e-01, 5.5450e-01, 3.7606e-01, 3.3476e-01, 2.9833e-01,\n",
       "            3.0799e-01, 3.8857e-01, 5.2790e-01, 6.7798e-01, 7.1376e-01,\n",
       "            5.6532e-01, 4.4312e-01, 2.4508e-01, 3.1563e-02, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2463e-01,\n",
       "            1.7063e-01, 2.6290e-01, 4.0728e-01, 5.9260e-01, 6.1660e-01,\n",
       "            6.0305e-01, 5.1248e-01, 3.2929e-01, 2.9217e-01, 2.8432e-01,\n",
       "            3.2938e-01, 4.2588e-01, 5.6765e-01, 7.1135e-01, 7.1963e-01,\n",
       "            5.8073e-01, 4.3719e-01, 2.6369e-01, 8.5574e-02, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8475e-02,\n",
       "            1.4977e-01, 2.6220e-01, 4.2787e-01, 6.0446e-01, 6.0677e-01,\n",
       "            5.7436e-01, 4.5492e-01, 2.8198e-01, 2.4702e-01, 2.8403e-01,\n",
       "            3.6900e-01, 4.8051e-01, 5.8665e-01, 6.9823e-01, 7.2521e-01,\n",
       "            5.4455e-01, 4.3077e-01, 2.8115e-01, 9.2164e-02, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6750e-02,\n",
       "            1.2882e-01, 2.4146e-01, 4.0556e-01, 5.9278e-01, 5.6626e-01,\n",
       "            5.2059e-01, 4.0607e-01, 2.4225e-01, 2.3598e-01, 2.9357e-01,\n",
       "            3.5223e-01, 4.7965e-01, 6.0273e-01, 6.7246e-01, 6.9016e-01,\n",
       "            5.3417e-01, 4.1207e-01, 2.5765e-01, 1.0155e-01, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            8.2825e-02, 2.2426e-01, 3.8642e-01, 5.5705e-01, 5.3434e-01,\n",
       "            4.5715e-01, 3.5827e-01, 2.2996e-01, 2.1048e-01, 2.9152e-01,\n",
       "            3.5009e-01, 4.8800e-01, 6.1755e-01, 6.8452e-01, 6.7177e-01,\n",
       "            5.2763e-01, 3.8165e-01, 2.4410e-01, 1.0794e-01, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            8.9231e-02, 2.4340e-01, 3.6229e-01, 5.0951e-01, 4.8204e-01,\n",
       "            4.3106e-01, 3.3274e-01, 2.1780e-01, 2.1956e-01, 2.9225e-01,\n",
       "            3.8806e-01, 5.2238e-01, 6.2488e-01, 6.9315e-01, 7.1976e-01,\n",
       "            5.6420e-01, 4.2210e-01, 2.7263e-01, 1.2976e-01, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2968e-02,\n",
       "            1.0662e-01, 2.4012e-01, 3.5281e-01, 4.7537e-01, 4.4997e-01,\n",
       "            4.0613e-01, 3.0423e-01, 2.1381e-01, 2.3498e-01, 3.0403e-01,\n",
       "            4.1388e-01, 5.3733e-01, 6.3603e-01, 6.8340e-01, 6.8803e-01,\n",
       "            5.5685e-01, 3.8318e-01, 2.0786e-01, 7.9508e-02, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2269e-03,\n",
       "            7.9770e-02, 2.1428e-01, 3.2918e-01, 4.3973e-01, 4.1909e-01,\n",
       "            3.6316e-01, 2.6457e-01, 1.9366e-01, 2.1540e-01, 2.9355e-01,\n",
       "            4.0527e-01, 5.3865e-01, 6.4918e-01, 6.8314e-01, 6.8448e-01,\n",
       "            5.1648e-01, 3.0211e-01, 1.3535e-01, 6.2003e-04, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5052e-02,\n",
       "            1.1052e-01, 2.3281e-01, 3.2211e-01, 4.5243e-01, 4.2442e-01,\n",
       "            3.8048e-01, 2.8697e-01, 1.9344e-01, 2.4685e-01, 3.0787e-01,\n",
       "            4.1684e-01, 5.3850e-01, 6.2950e-01, 6.8454e-01, 6.6005e-01,\n",
       "            4.3923e-01, 2.3905e-01, 5.9975e-02, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7669e-02,\n",
       "            1.0335e-01, 2.2435e-01, 3.3004e-01, 4.5369e-01, 4.4165e-01,\n",
       "            4.0069e-01, 3.2317e-01, 2.5881e-01, 3.0631e-01, 4.0167e-01,\n",
       "            5.1954e-01, 6.3440e-01, 7.0906e-01, 6.8501e-01, 5.6824e-01,\n",
       "            3.2537e-01, 1.1527e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0766e-02,\n",
       "            9.0937e-02, 2.1928e-01, 3.2003e-01, 4.4709e-01, 4.2568e-01,\n",
       "            3.9727e-01, 3.3264e-01, 2.5427e-01, 3.4208e-01, 4.5658e-01,\n",
       "            5.7438e-01, 7.1744e-01, 7.5836e-01, 6.7652e-01, 5.5978e-01,\n",
       "            2.9525e-01, 6.9945e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            8.4686e-02, 2.1654e-01, 3.0375e-01, 4.4718e-01, 4.1224e-01,\n",
       "            3.5762e-01, 3.2733e-01, 2.7905e-01, 3.8915e-01, 5.0041e-01,\n",
       "            5.7462e-01, 6.5017e-01, 6.8063e-01, 6.0425e-01, 4.5378e-01,\n",
       "            1.6777e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 2.4482e-02],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            6.5501e-02, 1.9119e-01, 2.8345e-01, 4.2797e-01, 3.9672e-01,\n",
       "            3.2831e-01, 3.0862e-01, 3.0910e-01, 4.0737e-01, 5.4764e-01,\n",
       "            6.1904e-01, 6.4719e-01, 6.7028e-01, 5.6418e-01, 3.7486e-01,\n",
       "            8.8547e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 4.5851e-02],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2727e-02,\n",
       "            9.3619e-02, 2.2058e-01, 3.0533e-01, 4.1068e-01, 3.8101e-01,\n",
       "            3.3991e-01, 3.3951e-01, 3.3827e-01, 4.4221e-01, 5.6407e-01,\n",
       "            5.9115e-01, 6.0963e-01, 5.7517e-01, 4.6586e-01, 3.5370e-01,\n",
       "            7.2625e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 9.7129e-02],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3563e-02,\n",
       "            8.7211e-02, 2.0267e-01, 2.6754e-01, 3.6032e-01, 3.4092e-01,\n",
       "            3.2496e-01, 3.6031e-01, 3.9626e-01, 4.7103e-01, 5.7030e-01,\n",
       "            5.7300e-01, 5.4087e-01, 5.0672e-01, 4.0759e-01, 3.1683e-01,\n",
       "            4.8207e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 5.0976e-02],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            4.7083e-02, 1.4543e-01, 1.9985e-01, 3.0619e-01, 3.0374e-01,\n",
       "            3.2617e-01, 3.7533e-01, 4.1455e-01, 4.6626e-01, 5.3606e-01,\n",
       "            4.9028e-01, 4.3386e-01, 3.8550e-01, 2.9431e-01, 2.5413e-01,\n",
       "            6.0886e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 2.8689e-02],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            1.5534e-02, 1.0733e-01, 1.5938e-01, 2.6700e-01, 2.7782e-01,\n",
       "            3.3720e-01, 3.8693e-01, 4.0901e-01, 4.4904e-01, 4.7081e-01,\n",
       "            4.0891e-01, 3.5681e-01, 3.1131e-01, 2.5070e-01, 2.3102e-01,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7397e-02, 8.9746e-02,\n",
       "            1.5331e-01, 1.8382e-01, 2.1456e-01, 2.3863e-01, 2.3842e-01,\n",
       "            2.1562e-01, 1.7428e-01, 1.4600e-01, 1.1530e-01, 9.4409e-02,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            3.5238e-02, 5.2549e-02, 6.4157e-02, 8.3935e-02, 7.0463e-02,\n",
       "            5.2264e-02, 3.7297e-02, 8.7203e-03, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            6.2152e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00]]]]),\n",
       " tensor([[[[0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0.]]]]),\n",
       " tensor([[[[0.8350, 1.2800, 0.8552, 0.9745, 1.0358, 1.0369, 1.0880],\n",
       "           [0.8035, 1.1977, 0.8240, 0.8038, 0.9366, 1.2934, 0.9635],\n",
       "           [0.7993, 1.2085, 0.8188, 0.6236, 1.1553, 1.0960, 0.8452],\n",
       "           [0.8821, 1.1956, 0.8120, 0.8252, 1.4144, 1.0057, 0.8570],\n",
       "           [0.9095, 1.0261, 0.6830, 0.8805, 1.3807, 0.8380, 0.8154],\n",
       "           [0.9159, 0.9382, 0.7902, 1.1564, 1.0831, 0.8161, 0.8956],\n",
       "           [0.9511, 1.0121, 0.9940, 1.1217, 0.9584, 0.9125, 0.9437]]]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test = dataset.data[784].unsqueeze(0).unsqueeze(0).float() / 255\n",
    "    predict = model(test)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[0][0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Увеличение эпох с 2 до 10 только сделало четче ту же область,\n",
    "#    код выполнялся около 1часа, VAE сильно мылит изображение. Необходимо уменьшить ядро в свертках?\n",
    "\n",
    "plt.imshow(predict[0][0][0].detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test[0].view(28, 28).detach().numpy())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8750a921b84a1b624817dbfae33fa28d408c1c697f0b181b4279f7947f553d12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
